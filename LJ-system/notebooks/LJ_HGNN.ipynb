{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # LJ HGNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training HGNN on LJ graphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################## IMPORT ######################\n",
    "################################################\n",
    "import sys\n",
    "MAINPATH = \"..\"  # nopep8\n",
    "sys.path.append(MAINPATH)  # nopep8\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from typing import Callable, Sequence\n",
    "from src import io\n",
    "from src.lgnn_batch import mkgraph\n",
    "import importlib\n",
    "from IPython.display import display, clear_output\n",
    "from frozendict import frozendict\n",
    "from typing import Any, Callable, Iterable, Mapping, Optional, Union\n",
    "import jax.tree_util as tree\n",
    "from flax import linen as nn\n",
    "from typing import Any, NamedTuple, Iterable, Mapping, Union, Optional\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from functools import partial, wraps\n",
    "from statistics import mode\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from jax import jit, random, value_and_grad, vmap\n",
    "from jax.experimental import optimizers\n",
    "from jax.config import config\n",
    "\n",
    "from jax_md import space\n",
    "\n",
    "import jraph\n",
    "\n",
    "from shadow.plot import *\n",
    "\n",
    "import src\n",
    "from src import lnn\n",
    "import src.graph as gr\n",
    "# from src.lnn import accelerationFull\n",
    "from src.md import prediction\n",
    "from src.models import MSE, initialize_mlp\n",
    "from src.nve import nve\n",
    "from src.utils import *\n",
    "import src.utils as util\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "config.update(\"jax_check_tracer_leaks\", False)\n",
    "# jax.config.update('jax_platform_name', 'gpu')\n",
    "def rcParams_Set():\n",
    "    plt.rcParams['font.weight']='normal'\n",
    "    plt.rcParams[\"axes.labelweight\"] = \"normal\"\n",
    "\n",
    "rcParams_Set()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "ArrayTree = Union[jnp.ndarray,\n",
    "                  Iterable['ArrayTree'], Mapping[Any, 'ArrayTree']]\n",
    "\n",
    "\n",
    "class GraphsTuple(NamedTuple):\n",
    "    nodes: Optional[ArrayTree]\n",
    "    edges: Optional[ArrayTree]\n",
    "    receivers: Optional[jnp.ndarray]  # with integer dtype\n",
    "    senders: Optional[jnp.ndarray]  # with integer dtype\n",
    "    globals: Optional[ArrayTree]\n",
    "    n_node: jnp.ndarray  # with integer dtype\n",
    "    n_edge: jnp.ndarray   # with integer dtype\n",
    "    e_order: Optional[jnp.ndarray]\n",
    "    e_mask: jnp.ndarray\n",
    "    n_mask: jnp.ndarray\n",
    "\n",
    "\n",
    "dataloc = \"../data/LJ_125\"\n",
    "# graphs, _ = src.io.loadfile(f\"{dataloc}/graphs/graphs_dicts_lammps_cutoff.pkl\")\n",
    "GRAPHS, _ = src.io.loadfile(f\"{dataloc}/graphs/mkgraphs_dicts_lammps_cutoff.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Set directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = len(GRAPHS)\n",
    "\n",
    "randfilename = datetime.now().strftime(\n",
    "    \"%m-%d-%Y_%H-%M-%S\") + f\"_{datapoints}\"\n",
    "\n",
    "out_dir = dataloc+\"/HGNN_redo/\"\n",
    "\n",
    "loadmodel = util.fileloc(src.models.loadmodel, out_dir+\"/models/\")\n",
    "savemodel = util.fileloc(src.models.savemodel, out_dir+\"/models/\")\n",
    "\n",
    "loadfile = util.fileloc(src.io.loadfile, out_dir)\n",
    "savefile = util.fileloc(src.io.savefile, out_dir)\n",
    "\n",
    "save_ovito = util.fileloc(src.io.save_ovito, out_dir+\"/ovito/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################## CONFIG ######################\n",
    "################################################\n",
    "L = 3.9685026299204984 #graphs[0][\"L\"]\n",
    "atoms = {'A': 60, 'B': 15} # graphs[0][\"atoms\"]\n",
    "displacement_fn, shift_fn = space.periodic(L)\n",
    "\n",
    "def shift(R, dR, V):\n",
    "    return shift_fn(R, dR), V\n",
    "\n",
    "def displacement(R1, R2):\n",
    "    return vmap(displacement_fn, in_axes=(0, 0))(R1, R2)\n",
    "\n",
    "np.random.seed(seed)\n",
    "key = random.PRNGKey(seed)\n",
    "mask = np.random.choice(len(GRAPHS), len(GRAPHS), replace=False)\n",
    "\n",
    "try:\n",
    "    dataset_states = [g for g, m in zip(GRAPHS, mask) if m]\n",
    "except:\n",
    "    raise Exception(\"Generate dataset first.\")\n",
    "\n",
    "if datapoints is not None:\n",
    "    dataset_states = dataset_states[:datapoints]\n",
    "\n",
    "state = dataset_states[0]\n",
    "\n",
    "N, dim = state.nodes[\"position\"].shape\n",
    "\n",
    "Aatoms, Batoms = atoms.values()\n",
    "Natoms = sum(atoms.values())\n",
    "# species = GRAPHS[0].nodes[\"type\"][:-1]\n",
    "species = np.load(f'{dataloc}/lamp_data/species.npy')\n",
    "# species = jnp.where(jnp.arange(N) >= Batoms, 1, 0)\n",
    "# species.sum()\n",
    "masses = jnp.where(jnp.arange(N) >= Aatoms, 1.0, 1.0)\n",
    "print(N, Batoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_func(f, key=[], apply=None):\n",
    "    def func(g, params, *args, **kwargs):\n",
    "        nodes, *extra = g\n",
    "        b = {k: v for k, v in nodes.items() if k not in key}\n",
    "        a = {k: v for k, v in nodes.items() if k in key}\n",
    "        \n",
    "        def fn(a):\n",
    "            b.update(a)\n",
    "            ng = GraphsTuple(b, *extra)\n",
    "            return f(ng, params)\n",
    "        if apply is None:\n",
    "            return fn(a)\n",
    "        else:\n",
    "            return apply(fn, *args, **kwargs)(a)\n",
    "    return func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Sequence\n",
    "\n",
    "from flax import linen as nn\n",
    "import jax.numpy as jnp\n",
    "import jraph\n",
    "\n",
    "def squareplus(x):\n",
    "    return jax.lax.mul(0.5,\n",
    "                       jax.lax.add(x, jax.lax.sqrt(jax.lax.add(jax.lax.square(x), 4.0))))\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"A multi-layer perceptron.\"\"\"\n",
    "    \n",
    "    feature_sizes: Sequence[int]\n",
    "    dropout_rate: float = 0\n",
    "    deterministic: bool = True\n",
    "    activation: Callable[[jnp.ndarray], jnp.ndarray] = squareplus\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for size in self.feature_sizes:\n",
    "            x = nn.Dense(features=size)(x)\n",
    "            x = self.activation(x)\n",
    "            x = nn.Dropout(\n",
    "                rate=self.dropout_rate, deterministic=self.deterministic)(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.tree_util as tree\n",
    "from typing import Any, Callable, Iterable, Mapping, Optional, Union\n",
    "from frozendict import frozendict\n",
    "\n",
    "\n",
    "class LagrangianGraphNetwork(nn.Module):\n",
    "    \"\"\"A complete Lagrangian Graph Network model defined with Jraph.\"\"\"\n",
    "    num_species: int\n",
    "    \n",
    "    node_global_latent_size: int = 8\n",
    "    node_mp_latent_size: int = 8\n",
    "    edge_mp_latent_size: int = 8\n",
    "    layer_hidden_dim: int = 16\n",
    "    num_mlp_layers: int = 2\n",
    "    message_passing_steps: int = 1\n",
    "    output_globals_size: int = 0\n",
    "    mlp_activation = squareplus\n",
    "    \n",
    "    edge_global_latent_size: int = None\n",
    "    \n",
    "    dropout_rate: float = 0\n",
    "    skip_connections: bool = True\n",
    "    use_edge_model: bool = True\n",
    "    use_ke_model: bool = True\n",
    "    layer_norm: bool = True\n",
    "    deterministic: bool = True\n",
    "    \n",
    "    initial_edge_embed_fn: Callable = None\n",
    "    initial_node_embed_fn: Callable = None\n",
    "    edge_update_fn: Callable = None\n",
    "    node_update_fn: Callable = None\n",
    "    \n",
    "    KE_fn: Callable = None\n",
    "    PE_fn: Callable = None\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        if self.layer_norm:\n",
    "            return nn.LayerNorm()(x)\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def onehot(self, n):\n",
    "        def fn(n):\n",
    "            out = jax.nn.one_hot(n, self.num_species*(self.num_species+1) // 2)\n",
    "            return out\n",
    "        out = vmap(fn)(n.reshape(-1,))\n",
    "        return out\n",
    "    \n",
    "    def linear_global_node_embed(self, x, *args, **kwargs):\n",
    "        return nn.Dense(self.node_global_latent_size, *args, **kwargs)(x)\n",
    "    \n",
    "    def linear_mp_node_embed(self, x, *args, **kwargs):\n",
    "        return nn.Dense(self.node_mp_latent_size, *args, **kwargs)(x)\n",
    "    \n",
    "    def linear_mp_edge_embed(self, x, *args, **kwargs):\n",
    "        return nn.Dense(self.edge_mp_latent_size, *args, **kwargs)(x)\n",
    "    \n",
    "    def setup(self):\n",
    "        pass\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, graphs: GraphsTuple) -> GraphsTuple:\n",
    "        \n",
    "        nodes, edges, receivers, senders, globals_, n_node, n_edge, eorder, emask, nmask = graphs\n",
    "        \n",
    "        # Equivalent to jnp.sum(n_node), but jittable\n",
    "        # calculate number of nodes in graph\n",
    "        sum_n_node = tree.tree_leaves(nodes)[0].shape[0]\n",
    "        \n",
    "        # calculate number of edges in graph\n",
    "        sum_n_edge = senders.shape[0]\n",
    "        \n",
    "        # check if all all node array are of same length = number of nodes\n",
    "        if not tree.tree_all(\n",
    "                tree.tree_map(lambda n: n.shape[0] == sum_n_node, nodes)):\n",
    "            raise ValueError(\n",
    "                'All node arrays in nest must contain the same number of nodes.')\n",
    "        \n",
    "        # Initial sent info\n",
    "        sent_attributes = tree.tree_map(lambda n: n[senders], nodes)\n",
    "        \n",
    "        # Initial received info\n",
    "        received_attributes = tree.tree_map(lambda n: n[receivers], nodes)\n",
    "        \n",
    "        # Here we scatter the global features to the corresponding edges,\n",
    "        # giving us tensors of shape [num_edges, global_feat].\n",
    "        # i.e create an array per edge for global attributes\n",
    "        global_edge_attributes = tree.tree_map(lambda g: jnp.repeat(\n",
    "            g, n_edge, axis=0, total_repeat_length=sum_n_edge), globals_)\n",
    "        \n",
    "        # Here we scatter the global features to the corresponding nodes,\n",
    "        # giving us tensors of shape [num_nodes, global_feat].\n",
    "        # i.e create an array per node for global attributes\n",
    "        global_node_attributes = tree.tree_map(lambda g: jnp.repeat(\n",
    "            g, n_node, axis=0, total_repeat_length=sum_n_node), globals_)\n",
    "        \n",
    "        # We will first linearly project the original features as 'embeddings'.\n",
    "        # apply inital edge embedding\n",
    "        if self.initial_edge_embed_fn:\n",
    "            edges = self.initial_edge_embed_fn(self, edges, sent_attributes, received_attributes,\n",
    "                                               global_edge_attributes)\n",
    "        # apply initial node embeddings\n",
    "        if self.initial_node_embed_fn:\n",
    "            nodes = self.initial_node_embed_fn(self, nodes, sent_attributes,\n",
    "                                               received_attributes, global_node_attributes)\n",
    "        \n",
    "        # Now, we will apply a Graph Network once for each message-passing round.\n",
    "        # mlp_feature_sizes = [self.latent_size] * self.num_mlp_layers\n",
    "        for _ in range(self.message_passing_steps):\n",
    "            if self.node_update_fn:\n",
    "                nodes = self.node_update_fn(self,\n",
    "                                            nodes, edges, senders, receivers,\n",
    "                                            global_node_attributes, sum_n_node)\n",
    "            \n",
    "            if self.edge_update_fn:\n",
    "                senders_attributes = tree.tree_map(\n",
    "                    lambda n: n[senders], nodes)\n",
    "                receivers_attributes = tree.tree_map(\n",
    "                    lambda n: n[receivers], nodes)\n",
    "                edges = self.edge_update_fn(self, edges, senders_attributes, receivers_attributes,\n",
    "                                            global_edge_attributes, eorder, _+1 == self.message_passing_steps)\n",
    "        \n",
    "        KE = 0.0\n",
    "        if self.KE_fn:\n",
    "            KE = KE + self.KE_fn(self, nodes, nmask=nmask)\n",
    "        \n",
    "        PEij, PEi = self.PE_fn(self, edges, nodes, senders, receivers, eorder,\n",
    "                               emask=emask, nmask=nmask, n_type=graphs.nodes['type'])\n",
    "        return PEij, PEi, KE, edges['dij']\n",
    "        \n",
    "        # return GraphsTuple(\n",
    "        #     nodes=nodes,\n",
    "        #     edges=edges,\n",
    "        #     receivers=receivers,\n",
    "        #     senders=senders,\n",
    "        #     globals=globals_,\n",
    "        #     n_node=n_node,\n",
    "        #     n_edge=n_edge,\n",
    "        #     e_order=eorder,\n",
    "        #     e_mask=emask,\n",
    "        #     n_mask=nmask\n",
    "        #     )\n",
    "\n",
    "\n",
    "def HGNN(*args, displacement_fn=None, **kwargs):\n",
    "    \n",
    "    ##################\n",
    "    ## EDGE UPDATES ##\n",
    "    ##################\n",
    "    \n",
    "    ##############\n",
    "    # EMBEDDING  #\n",
    "    ##############\n",
    "    \n",
    "    def fn_edge_embed(self, e):\n",
    "        def fn(ei):\n",
    "            out = self.linear_mp_edge_embed(ei, name=\"edge_embed_mp\")\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0))(e)\n",
    "        return out\n",
    "    \n",
    "    def initial_edge_embed_fn(self, edges, senders, receivers, globals_):\n",
    "        del edges, globals_\n",
    "        dr = displacement_fn(senders[\"position\"], receivers[\"position\"])\n",
    "        dij = jnp.sqrt(1e-10 + jnp.square(dr).sum(axis=1, keepdims=True))\n",
    "        eij = dij\n",
    "        emb = fn_edge_embed(self, eij)\n",
    "        return frozendict({\"edge_embed\": emb, \"dij\": dij})\n",
    "    \n",
    "    ##############\n",
    "    #   UPDATE   #\n",
    "    ##############\n",
    "    \n",
    "    def fn_edge(self, e, s, r):\n",
    "        def fn(hi, hj):\n",
    "            c2ij = hi * hj\n",
    "            mlp_feature_sizes = [self.layer_hidden_dim] * \\\n",
    "                self.num_mlp_layers + [self.edge_mp_latent_size]\n",
    "            out = MLP(mlp_feature_sizes,\n",
    "                      dropout_rate=self.dropout_rate,\n",
    "                      deterministic=self.deterministic)(c2ij)\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0, 0))(s, r)\n",
    "        out = self.normalize(out)\n",
    "        return e + out\n",
    "    \n",
    "    def edge_update_fn(self, edges, senders, receivers, globals_, eorder, last_step):\n",
    "        del globals_\n",
    "        emb = fn_edge(self, edges[\"edge_embed\"], senders[\"node_embed\"],\n",
    "                      receivers[\"node_embed\"])\n",
    "        return frozendict({\"edge_embed\": emb, \"dij\": edges[\"dij\"]})\n",
    "    \n",
    "    ##################\n",
    "    ## NODE UPDATES ##\n",
    "    ##################\n",
    "    \n",
    "    ##############\n",
    "    # EMBEDDING  #\n",
    "    ##############\n",
    "    \n",
    "    def fn_node_embed_ke(self, n):\n",
    "        def fn(ni):\n",
    "            out = self.linear_global_node_embed(ni, name=\"node_embed_ke\")\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0))(n)\n",
    "        return out\n",
    "    \n",
    "    def fn_node_embed_global(self, n):\n",
    "        def fn(ni):\n",
    "            out = self.linear_global_node_embed(ni, name=\"node_embed_global\")\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0))(n)\n",
    "        return out\n",
    "    \n",
    "    def fn_node_embed_mp(self, n):\n",
    "        def fn(ni):\n",
    "            out = self.linear_mp_node_embed(ni, name=\"node_embed_mp\")\n",
    "            return out\n",
    "        out = vmap(fn, in_axes=(0))(n)\n",
    "        return out\n",
    "    \n",
    "    def initial_node_embed_fn(self, nodes, sent_edges, received_edges, globals_):\n",
    "        del sent_edges, received_edges, globals_\n",
    "        type_of_node = nodes[\"type\"]\n",
    "        ohe = self.onehot(type_of_node)\n",
    "        \n",
    "        vel = jnp.sum(jnp.square(nodes[\"velocity\"]), axis=1, keepdims=True)\n",
    "        # vel = nodes[\"velocity\"]\n",
    "        \n",
    "        emb_vel = jnp.hstack(\n",
    "            [fn_node_embed_ke(self, ohe), vel])\n",
    "        \n",
    "        emb_pos = jnp.hstack(\n",
    "            [fn_node_embed_global(self, ohe), nodes[\"position\"]])\n",
    "        \n",
    "        emb_mp = fn_node_embed_mp(self, ohe)\n",
    "        \n",
    "        return frozendict({\"node_embed\": emb_mp,\n",
    "                           \"node_pos_embed\": emb_pos,\n",
    "                           \"node_vel_embed\": emb_vel,\n",
    "                           \"velocity\": nodes['velocity'],\n",
    "                           \"mass\": nodes[\"mass\"],\n",
    "                           })\n",
    "    \n",
    "    ##############\n",
    "    #   UPDATE   #\n",
    "    ##############\n",
    "    \n",
    "    def fn_node(self, n, e, s, r, sum_n_node):\n",
    "        c1ij = jnp.hstack([n[r], e])\n",
    "        mlp_feature_sizes = [self.layer_hidden_dim] * \\\n",
    "            self.num_mlp_layers + [self.node_mp_latent_size]\n",
    "        out = vmap(lambda x: MLP(mlp_feature_sizes,\n",
    "                                 dropout_rate=self.dropout_rate,\n",
    "                                 deterministic=self.deterministic)(x))(c1ij)\n",
    "        out = jax.ops.segment_sum(out, r, sum_n_node)\n",
    "        out = self.normalize(out)\n",
    "        return n + out\n",
    "    \n",
    "    def node_update_fn(self, nodes, edges, senders, receivers, globals_, sum_n_node):\n",
    "        del globals_\n",
    "        emb = fn_node(self, nodes[\"node_embed\"], edges[\"edge_embed\"],\n",
    "                      senders, receivers, sum_n_node)\n",
    "        n = dict(nodes)\n",
    "        n.update({\"node_embed\": emb})\n",
    "        return frozendict(n)\n",
    "    \n",
    "    ##################\n",
    "    ##  ENERGY CAL  ##\n",
    "    ##################\n",
    "    \n",
    "    ##############\n",
    "    ###   KE   ###\n",
    "    ##############\n",
    "    \n",
    "    def fn_node_ke(self, n):\n",
    "        def fn(ni):\n",
    "            mlp_feature_sizes = [self.layer_hidden_dim] * \\\n",
    "                self.num_mlp_layers + [1]\n",
    "            out = MLP(mlp_feature_sizes,\n",
    "                      dropout_rate=self.dropout_rate,\n",
    "                      deterministic=self.deterministic, name=\"MPL_KE\")(ni)\n",
    "            return out\n",
    "        out = vmap(fn)(n)\n",
    "        return out\n",
    "    \n",
    "    def KE_fn(self, nodes, nmask=None):\n",
    "        if self.use_ke_model:\n",
    "            t = fn_node_ke(self, nodes[\"node_vel_embed\"]).flatten()\n",
    "        else:\n",
    "            t = 0.5*(nodes[\"velocity\"]**2).sum(axis=1) * nodes[\"mass\"]\n",
    "        if nmask is not None:\n",
    "            return jnp.where(nmask, t, 0.0)\n",
    "        else:\n",
    "            return t\n",
    "    \n",
    "    ##############\n",
    "    ###   PE   ###\n",
    "    ##############\n",
    "    \n",
    "    def fn_node_l(self, n):\n",
    "        def fn(ni):\n",
    "            mlp_feature_sizes = [self.layer_hidden_dim] * \\\n",
    "                self.num_mlp_layers + [1]\n",
    "            out = MLP(mlp_feature_sizes,\n",
    "                      dropout_rate=self.dropout_rate,\n",
    "                      deterministic=self.deterministic, name=\"MPL_PE_NODE_L\")(ni)\n",
    "            return out\n",
    "        out = vmap(fn)(n)\n",
    "        return out\n",
    "    \n",
    "    def fn_edge_l(self, e_attr, sen_attr, rec_attr):\n",
    "        def fn(eij):\n",
    "            mlp_feature_sizes = [self.layer_hidden_dim] * \\\n",
    "                self.num_mlp_layers + [1]\n",
    "            out = MLP(mlp_feature_sizes,\n",
    "                      dropout_rate=self.dropout_rate,\n",
    "                      deterministic=self.deterministic, name=\"MPL_PE_EDGE_L\")(eij)\n",
    "            return out\n",
    "        out = vmap(fn)(e_attr)\n",
    "        return out\n",
    "    \n",
    "    def fn_node_g(self, n):\n",
    "        def fn(ni):\n",
    "            mlp_feature_sizes = [self.layer_hidden_dim] * \\\n",
    "                self.num_mlp_layers + [1]\n",
    "            out = MLP(mlp_feature_sizes,\n",
    "                      dropout_rate=self.dropout_rate,\n",
    "                      deterministic=self.deterministic, name=\"MPL_PE_NODE_G\")(ni)\n",
    "            return out\n",
    "        out = vmap(fn)(n)\n",
    "        return out\n",
    "    \n",
    "    def PE_fn(self, edges, nodes, senders, receivers, eorder, emask=None, nmask=None, n_type=None):\n",
    "        # VIJ = jnp.array([0.0])\n",
    "        # VI = jnp.array([0.0])\n",
    "        \n",
    "        if self.use_edge_model:\n",
    "            vij = fn_edge_l(self, edges[\"edge_embed\"] + edges[\"edge_embed\"][eorder], nodes[\"node_embed\"]\n",
    "                        [senders], nodes[\"node_embed\"][receivers]).flatten()\n",
    "            \n",
    "            if emask is not None:\n",
    "                vij = jnp.where(emask, vij, 0.0)\n",
    "            else:\n",
    "                print('emask is none')\n",
    "            \n",
    "            # VIJ += vij\n",
    "            return vij, jnp.array([0.0])\n",
    "        else:\n",
    "            # vij = vmap(lnn.LJ)(edges[\"dij\"]).flatten()\n",
    "            eij = edges[\"dij\"]\n",
    "            for a in range(2):\n",
    "                for b in range(2):\n",
    "                    ljmask = (n_type[senders] == a) & (n_type[receivers] == b)\n",
    "                    # ljmask = (eij >= 0.1) & ljmask\n",
    "                    if a==0 and b==0:\n",
    "                        pe_actual = 0.5*vmap(partial(lnn.LJ, sigma=1.0,epsilon=1.0))(eij).flatten()\n",
    "                        pe_actual_00 = jnp.where(ljmask, pe_actual, 0)\n",
    "                    elif a==0 and b==1:\n",
    "                        pe_actual = 0.5*vmap(partial(lnn.LJ, sigma=0.8,epsilon=1.5))(eij).flatten()\n",
    "                        pe_actual_01 = jnp.where(ljmask, pe_actual, 0)\n",
    "                    elif a==1 and b==0:\n",
    "                        pe_actual = 0.5*vmap(partial(lnn.LJ, sigma=0.8,epsilon=1.5))(eij).flatten()\n",
    "                        pe_actual_10 = jnp.where(ljmask, pe_actual, 0)\n",
    "                    elif a==1 and b==1:\n",
    "                        pe_actual = 0.5*vmap(partial(lnn.LJ, sigma=0.88,epsilon=0.5))(eij).flatten()\n",
    "                        pe_actual_11 = jnp.where(ljmask, pe_actual, 0)\n",
    "            \n",
    "            vij = pe_actual_00+pe_actual_01+pe_actual_10+pe_actual_11\n",
    "            if emask is not None:\n",
    "                vij = jnp.where(emask, vij, 0.0)\n",
    "            else:\n",
    "                print('emask is none')\n",
    "            # VIJ += vij\n",
    "            return vij, jnp.array([0.0])\n",
    "        \n",
    "        # # lj = vmap(lnn.LJ)(edges[\"dij\"]).flatten()\n",
    "        # # vij += lj\n",
    "        \n",
    "        # if emask is not None:\n",
    "        #     vij = jnp.where(emask, vij, 0.0)\n",
    "        # # else:\n",
    "        # #     print('emask is none')\n",
    "        \n",
    "        # VIJ += vij\n",
    "        \n",
    "        # # return VIJ, VI\n",
    "        # vi = fn_node_l(self, nodes[\"node_embed\"]).flatten()\n",
    "        # vi += fn_node_g(self, nodes[\"node_pos_embed\"]).flatten()\n",
    "        \n",
    "        # if nmask is None:\n",
    "        #     VI += vi\n",
    "        # else:\n",
    "        #     VI += jnp.where(nmask, vi, jnp.zeros(vi[0].shape))\n",
    "            \n",
    "        # return VIJ, VI\n",
    "    \n",
    "    return LagrangianGraphNetwork(*args,\n",
    "                                  initial_edge_embed_fn=initial_edge_embed_fn,\n",
    "                                  initial_node_embed_fn=initial_node_embed_fn,\n",
    "                                  node_update_fn=node_update_fn,\n",
    "                                  edge_update_fn=edge_update_fn,\n",
    "                                  KE_fn=KE_fn,\n",
    "                                  PE_fn=PE_fn,\n",
    "                                  **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![graph_architecture.png](attachment:e7d2e5c8-c36d-48a7-8a59-8e1fbc4ed6e2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Define lagrangian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_actual = HGNN(len(np.unique(species)),\n",
    "             displacement_fn=displacement,\n",
    "             layer_norm=True,\n",
    "             use_ke_model=False,\n",
    "             use_edge_model=False,\n",
    "             node_global_latent_size=10,\n",
    "             node_mp_latent_size=10,\n",
    "             edge_mp_latent_size=10,\n",
    "             layer_hidden_dim=10,\n",
    "             num_mlp_layers=2,\n",
    "             message_passing_steps=2,\n",
    "             )\n",
    "\n",
    "params = model_actual.init(key, GRAPHS[0])\n",
    "\n",
    "def Hactual(graph, params):\n",
    "    PEij, PEi, KE, _ = model_actual.apply(params, graph)\n",
    "    return KE.sum() + PEij.sum() #+ PEi.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HGNN(len(np.unique(species)),\n",
    "             displacement_fn=displacement,\n",
    "             layer_norm=True,\n",
    "             use_ke_model=True,\n",
    "             use_edge_model=True,\n",
    "             node_global_latent_size=10,\n",
    "             node_mp_latent_size=10,\n",
    "             edge_mp_latent_size=10,\n",
    "             layer_hidden_dim=10,\n",
    "             num_mlp_layers=2,\n",
    "             message_passing_steps=2,\n",
    "             )\n",
    "\n",
    "# print(model)\n",
    "params = model.init(key, GRAPHS[0])\n",
    "# print(list(params['params'].keys()))\n",
    "\n",
    "def Hmodel(graph, params):\n",
    "    PEij, PEi, KE, _ = model.apply(params, graph)\n",
    "    return KE.sum() + PEij.sum() #+ PEi.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(gr)\n",
    "\n",
    "# state_graph = samegraph(**graphs[0], globals=None)\n",
    "# state_graph.n_node\n",
    "\n",
    "# print(\"\\n\\nsame graph: \", Lmodel(state_graph, params))\n",
    "\n",
    "# state_graph = mkgraph(**graphs[0], max_edges=max_edges,  globals=None)\n",
    "# print(\"\\n\\ngraph with padding: \", Lmodel(state_graph, params))\n",
    "\n",
    "# state_graph2 = samegraph(**graphs[1],  globals=None)\n",
    "# print(\"\\n\\nsame graph 2: \", Lmodel(state_graph2, params))\n",
    "\n",
    "# state_graph2 = mkgraph(**graphs[1], max_edges=max_edges,  globals=None)\n",
    "# print(\"\\n\\ngraph 2 with padding: \", Lmodel(state_graph2, params))\n",
    "\n",
    "# state_graph2 = mkgraph(**graphs[1], max_edges=max_edges,  globals=None)\n",
    "# print(\"\\n\\ngraph 1+2 with padding: \",\n",
    "#       Lmodel(_batch([state_graph, state_graph2], jnp), params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps(*args):\n",
    "    for arg in args:\n",
    "        try:\n",
    "            print(arg.shape)\n",
    "        except:\n",
    "            print(arg)\n",
    "\n",
    "# def hamiltonian(x, p, params):\n",
    "#     \"\"\"\n",
    "#     hamiltonian calls lnn._H\n",
    "#     x: Vector\n",
    "#     p: Vector\n",
    "#     \"\"\"\n",
    "#     return None\n",
    "\n",
    "\n",
    "def get_zdot_lambda(N, Dim, hamiltonian, drag=None, constraints=None, external_force=None):\n",
    "    dim = N*Dim\n",
    "    I = jnp.eye(dim)\n",
    "    J = jnp.zeros((2*dim, 2*dim))\n",
    "    J = J.at[:dim, dim:].set(I)\n",
    "    J = J.at[dim:, :dim].set(-I)\n",
    "    # J = jax.numpy.ndarray.at(J, jax.ops.index[:dim, dim:], I)\n",
    "    # J = jax.numpy.ndarray.at(J, jax.ops.index[dim:, :dim], -I)\n",
    "    J2 = jnp.zeros((2*dim, 2*dim))\n",
    "    J2 = J2.at[:dim, :dim].set(I)\n",
    "    J2 = J2.at[dim:, dim:].set(I)\n",
    "    \n",
    "    def dH_dz(state_graph, params):\n",
    "        dH_dx = apply_func(hamiltonian, apply=jax.grad, key=[\n",
    "                           'position'])(state_graph, params)\n",
    "        # print(dH_dx['position'].flatten())\n",
    "        dH_dp = apply_func(hamiltonian, apply=jax.grad, key=[\n",
    "                           'velocity'])(state_graph, params)\n",
    "        # print(dH_dp['velocity'])\n",
    "        # dH_dx.values['position'],\n",
    "        # jnp.hstack([dH_dx, dH_dp])\n",
    "        return jnp.hstack([dH_dx['position'].flatten(), dH_dp['velocity'].flatten()])\n",
    "    \n",
    "    if drag is None:\n",
    "        def drag(state_graph, params):\n",
    "            return 0.0\n",
    "    \n",
    "    def dD_dz(state_graph, params):\n",
    "        dD_dx = apply_func(drag, apply=jax.grad, key=[\n",
    "                           'position'])(state_graph, params)\n",
    "        dD_dp = apply_func(drag, apply=jax.grad, key=[\n",
    "                           'velocity'])(state_graph, params)\n",
    "        return jnp.hstack([dD_dx['position'].flatten(), dD_dp['velocity'].flatten()])\n",
    "    \n",
    "    if external_force is None:\n",
    "        def external_force(state_graph, params):\n",
    "            return 0.0*state_graph.nodes[\"velocity\"]\n",
    "    \n",
    "    if constraints is None:\n",
    "        def constraints(state_graph, params):\n",
    "            return jnp.zeros((1, 2*dim))\n",
    "    \n",
    "    def fn_zdot(state_graph, params):\n",
    "        dH = dH_dz(state_graph, params)\n",
    "        dD = J2 @ dD_dz(state_graph, params)\n",
    "        dD = - J @ dD\n",
    "        F = jnp.hstack(\n",
    "            [jnp.zeros(dim), external_force(state_graph, params).flatten()])\n",
    "        F = -J @ F\n",
    "        S = dH + J2 @ dD + F\n",
    "        A = constraints(state_graph, params).reshape(-1, 2*dim)\n",
    "        Aᵀ = A.T\n",
    "        INV = jnp.linalg.pinv(A @ J @ Aᵀ)\n",
    "        λ = -INV @ A @ J @ S\n",
    "        zdot = J @ (S + Aᵀ @ λ)\n",
    "        return zdot.reshape(2*N, Dim)\n",
    "    \n",
    "    def lambda_force(state_graph, params):\n",
    "        dH = dH_dz(state_graph, params)\n",
    "        dD = J2 @ dD_dz(state_graph, params)\n",
    "        dD = - J @ dD\n",
    "        F = jnp.hstack(\n",
    "            [jnp.zeros(dim), external_force(state_graph, params).flatten()])\n",
    "        F = -J @ F\n",
    "        S = dH + J2 @ dD + F\n",
    "        A = constraints(state_graph, params).reshape(-1, 2*dim)\n",
    "        Aᵀ = A.T\n",
    "        INV = jnp.linalg.pinv(A @ J @ Aᵀ)\n",
    "        λ = -INV @ A @ J @ S\n",
    "        return (J @ Aᵀ @ λ).reshape(2*N, Dim)\n",
    "    return fn_zdot, lambda_force\n",
    "\n",
    "\n",
    "def get_constraints(N, Dim, phi_, mass=None):\n",
    "    if mass is None:\n",
    "        mass = 1.0\n",
    "    \n",
    "    def phi(x): return phi_(x.reshape(N, Dim))\n",
    "    \n",
    "    def phidot(x, p):\n",
    "        Dphi = jax.jacobian(phi)(x.flatten())\n",
    "        pm = (p.flatten() / mass)\n",
    "        return Dphi @ pm\n",
    "    \n",
    "    def psi(z):\n",
    "        x, p = jnp.split(z, 2)\n",
    "        return jnp.vstack([phi(x), phidot(x, p)])\n",
    "    \n",
    "    def Dpsi(z):\n",
    "        return jax.jacobian(psi)(z)\n",
    "    \n",
    "    def fn(x, p, params):\n",
    "        z = jnp.vstack([x, p])\n",
    "        return Dpsi(z)\n",
    "    \n",
    "    return fn\n",
    "\n",
    "\n",
    "# def z(x, p): return jnp.vstack([x, p])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Parallel graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_graphs(graphs, size=8):\n",
    "    nbatches = len(graphs) // size\n",
    "    return [jax.tree_multimap(lambda *x: jnp.stack(x), *graphs[i*size:(i+1)*size]) for i in range(nbatches)]\n",
    "\n",
    "\n",
    "BGRAPHS = concat_graphs(GRAPHS, size=4)\n",
    "\n",
    "zdot_model, lamda_force_model = get_zdot_lambda(\n",
    "    *BGRAPHS[0].nodes[\"position\"].shape[-2:], Hmodel)\n",
    "\n",
    "zdot_actual, lamda_force_actual = get_zdot_lambda(\n",
    "    *BGRAPHS[0].nodes[\"position\"].shape[-2:], Hactual)\n",
    "\n",
    "\n",
    "# zdot_model(BGRAPHS[0], params).shape\n",
    "print((vmap(zdot_model, in_axes=(0, None))(BGRAPHS[0], params)).shape)\n",
    "print((vmap(zdot_actual, in_axes=(0, None))(BGRAPHS[0], params)).shape)\n",
    "# print((vmap(acc_fn, in_axes=(0, None))(BGRAPHS[0], params)).shape)\n",
    "\n",
    "# Zdots  = vmap(zdot_model, in_axes=(0, None))(BGRAPHS[0], params)\n",
    "\n",
    "# Zdots.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### LOSS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################## ML Training #################\n",
    "################################################\n",
    "# g = GRAPHS[0]\n",
    "# print(jnp.vstack([g.nodes[\"velocity\"], g.nodes[\"acceleration\"]]).shape)\n",
    "\n",
    "@jit\n",
    "def loss_fn(params, graph):\n",
    "    nmask = jnp.hstack([graph.n_mask,graph.n_mask])\n",
    "    A = zdot_model(graph, params)\n",
    "    # w = graph.nodes[\"prob\"]\n",
    "    w = 1\n",
    "    A_pr = jnp.vstack([graph.nodes[\"velocity\"], graph.nodes[\"acceleration\"]])\n",
    "    squared_error = (jnp.square(A - A_pr) * w).sum(axis=1)\n",
    "    return jnp.where(nmask, squared_error, 0.0).mean()\n",
    "\n",
    "\n",
    "vloss_fn = lambda *args: vmap(loss_fn, in_axes=(None, 0))(*args).mean()\n",
    "\n",
    "\n",
    "@jit\n",
    "def gloss(*args, **kwargs):\n",
    "    return value_and_grad(vloss_fn)(*args, **kwargs)\n",
    "\n",
    "\n",
    "# gloss(params, state_graph)\n",
    "\n",
    "opt_init, opt_update_, get_params = optimizers.adam(lr)\n",
    "\n",
    "\n",
    "@ jit\n",
    "def opt_update(i, grads_, opt_state):\n",
    "    grads_ = jax.tree_map(jnp.nan_to_num, grads_)\n",
    "    grads_ = jax.tree_map(\n",
    "        partial(jnp.clip, a_min=-1000.0, a_max=1000.0), grads_)\n",
    "    return opt_update_(i, grads_, opt_state)\n",
    "\n",
    "\n",
    "@jit\n",
    "def update(i, opt_state, params, loss__, *data):\n",
    "    \"\"\" Compute the gradient for a batch and update the parameters \"\"\"\n",
    "    value, grads_ = gloss(params, *data)\n",
    "    opt_state = opt_update(i, grads_, opt_state)\n",
    "    return opt_state, get_params(opt_state), value\n",
    "\n",
    "\n",
    "@ jit\n",
    "def step(i, ps, *args, **kwargs):\n",
    "    return update(i, *ps, *args, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_energy_plot(ax,_model,_params,_graph):\n",
    "    # g = GRAPHS[0]\n",
    "    # vij, vi, KE, drij = model.apply(params, g)\n",
    "    vij, vi, KE, drij = _model.apply(_params,_graph)\n",
    "        \n",
    "    eij = jnp.sqrt(1e-10 + jnp.square(drij).sum(axis=1))\n",
    "    \n",
    "    types_ = jnp.unique(_graph.nodes[\"type\"])\n",
    "    \n",
    "    for a in range(len(types_)):\n",
    "        for b in range(len(types_)):\n",
    "            \n",
    "            mask = (_graph.nodes[\"type\"][_graph.senders] == a) & (\n",
    "                _graph.nodes[\"type\"][_graph.receivers] == b)\n",
    "            mask = (eij >= 0.1) & mask\n",
    "            \n",
    "            y = vij[mask]\n",
    "            x = eij[mask]\n",
    "            \n",
    "            mask = jnp.argsort(x)\n",
    "            x = x[mask]\n",
    "            y = y[mask]\n",
    "            y -= y[-1]\n",
    "            ax.plot(x, y, '.',label=f\"{a}-{b}\")\n",
    "    # ax.set_xlim([-2,2])\n",
    "    # ax.set_ylim([-2,1])\n",
    "    ax.set_xlabel(\"e$_{ij}$\")\n",
    "    ax.set_ylabel(\"V$_{ij}$\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "make_energy_plot(ax,model,params,GRAPHS[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_state = opt_init(params)\n",
    "epoch = 0\n",
    "optimizer_step = -1\n",
    "larray = [0.0]\n",
    "ltarray = [0.0]\n",
    "\n",
    "\n",
    "epochs = 50000\n",
    "saveat = 20\n",
    "plotat = 100\n",
    "\n",
    "\n",
    "def bDATA(n): return [BGRAPHS[i]\n",
    "                      for i in np.random.choice(len(BGRAPHS), n, replace=False)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_energy_plot_(ax):\n",
    "    g = GRAPHS[0]\n",
    "    vij, vi, KE, drij = model.apply(params, g)\n",
    "    \n",
    "    eij = jnp.sqrt(1e-10 + jnp.square(drij).sum(axis=1))\n",
    "    \n",
    "    types_ = jnp.unique(g.nodes[\"type\"])\n",
    "    \n",
    "    for a in range(len(types_)):\n",
    "        for b in range(len(types_)):\n",
    "            \n",
    "            mask = (g.nodes[\"type\"][g.senders] == a) & (\n",
    "                g.nodes[\"type\"][g.receivers] == b)\n",
    "            mask = (eij >= 0.1) & mask\n",
    "            \n",
    "            y = vij[mask]\n",
    "            x = eij[mask]\n",
    "            \n",
    "            mask = jnp.argsort(x)\n",
    "            x = x[mask]\n",
    "            y = y[mask]\n",
    "            y -= y[-1]\n",
    "            ax.plot(x, y, label=f\"{a}-{b}\")\n",
    "    # ax.set_xlim([-2,2])\n",
    "    ax.set_ylim([-2,1])\n",
    "    ax.set_xlabel(\"e$_{ij}$\")\n",
    "    ax.set_ylabel(\"V$_{ij}$\")\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vzdot_model = jit(lambda *args: vmap(zdot_model, in_axes=(0, None))(*args))\n",
    "\n",
    "\n",
    "def get_acceleration(graph, params):\n",
    "    # x = jnp.hstack([graph.nodes[\"velocity\"], graph.nodes[\"acceleration\"]])\n",
    "    x = (jnp.hstack([graph.nodes[\"velocity\"], graph.nodes[\"acceleration\"]])[\n",
    "         :, :-1, :]).flatten()\n",
    "    # y = vzdot_model(graph, params)\n",
    "    # print(x.shape,y.shape)\n",
    "    y = (vzdot_model(graph, params)[:, :-1, :]).flatten()\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# %%\n",
    "nbatch = 20\n",
    "last_loss = 1e6\n",
    "epochs=1\n",
    "for epoch in range(epochs+1):\n",
    "    l = 0.0    \n",
    "    # for ind, data in enumerate(tqdm(bDATA(nbatch), desc=\"batched dataset\", colour=\"magenta\")):\n",
    "    for ind, data in enumerate(bDATA(nbatch)):\n",
    "        optimizer_step += 1\n",
    "        opt_state, params, l_ = step(\n",
    "            optimizer_step, (opt_state, params, 0), data)\n",
    "        l += l_\n",
    "    \n",
    "    if epoch % saveat == 0:\n",
    "        larray += [l/nbatch]\n",
    "        # ltarray += [loss_fn(params, Rst, Vst, Fst)]\n",
    "        print(f\"Epoch: {epoch+1}/{epochs+1} Loss (MSE):  train={larray[-1]}, test={ltarray[-1]}\")\n",
    "        # tqdm.write(\n",
    "        #     f\"Epoch: {epoch+1}/{epochs+1} Loss (MSE):  train={larray[-1]}, test={ltarray[-1]}\"\n",
    "        # )\n",
    "        if last_loss > larray[-1]:\n",
    "                    last_loss = larray[-1]\n",
    "                    savefile(f\"oneh_hgnn_trained_model16march_low_2.dil\", params, metadata={\"savedat\": epoch}, verbose=True)\n",
    "            \n",
    "    if epoch % plotat == 0:\n",
    "        clear_output(wait=True)\n",
    "        x = jnp.hstack([get_acceleration(g, params)[0] for g in BGRAPHS[:1]])\n",
    "        y = jnp.hstack([get_acceleration(g, params)[1] for g in BGRAPHS[:1]])\n",
    "        print(f\"R$^2$ = {r2_score(x, y):.2f}\")\n",
    "        fig, axs = panel(1, 3)\n",
    "        make_energy_plot_(axs[0])\n",
    "        _min = min(x.min(), y.min())\n",
    "        _max = max(x.max(), y.max())\n",
    "        _range = [_min, _max]\n",
    "        axs[1].scatter(x.flatten(), y.flatten(), s=20, alpha=0.3, ec=\"none\")\n",
    "        ax2 = plt.twinx(axs[1])\n",
    "        # ax2.plot(x.flatten().sort(), KDE_prob(x.flatten().sort()), color=\"r\")\n",
    "        axs[1].plot(_range, _range)\n",
    "        axs[2].semilogy(larray)\n",
    "        plt.show()\n",
    "        \n",
    "savefile(f\"oneh_hgnn_trained_model.dil\", params, metadata={\"savedat\": epoch}, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, _ = loadfile(f\"oneh_hgnn_trained_model.dil\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "make_energy_plot(ax,model,params,GRAPHS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_graph = GRAPHS[0]\n",
    "\n",
    "vij, _, _, drij = model.apply(params,_graph)\n",
    "eij = jnp.sqrt(1e-10 + jnp.square(drij).sum(axis=1))\n",
    "s_type = _graph.nodes[\"type\"][_graph.senders]\n",
    "r_type = _graph.nodes[\"type\"][_graph.receivers]\n",
    "\n",
    "# savefile(\"fig4_data_vij_eij_s_type_r_type.pkl\", (vij,eij,s_type,r_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "_graph = GRAPHS[0]\n",
    "\n",
    "eij = jnp.sqrt(1e-10 + jnp.square(drij).sum(axis=1))\n",
    "s_type = _graph.nodes[\"type\"][_graph.senders]\n",
    "r_type = _graph.nodes[\"type\"][_graph.receivers]\n",
    "\n",
    "for a in range(2):\n",
    "    for b in range(2):\n",
    "        \n",
    "        mask = (s_type == a) & (r_type == b)\n",
    "        mask = (eij >= 0.1) & mask\n",
    "        \n",
    "        y = vij[mask]\n",
    "        x = eij[mask]\n",
    "        \n",
    "        mask = jnp.argsort(x)\n",
    "        x = x[mask]\n",
    "        y = y[mask]\n",
    "        y -= y[-1]\n",
    "        ax.plot(x, y, '.',label=f\"{a}-{b}\")\n",
    "# ax.set_xlim([-2,2])\n",
    "# ax.set_ylim([-2,1])\n",
    "ax.set_xlabel(\"e$_{ij}$\")\n",
    "ax.set_ylabel(\"V$_{ij}$\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vzdot_model = jit(lambda *args: vmap(zdot_model, in_axes=(0, None))(*args))\n",
    "\n",
    "def get_acceleration(graph, params):    \n",
    "    # x = (jnp.hstack([graph.nodes[\"velocity\"], graph.nodes[\"acceleration\"]])[:, :-1, :]).flatten()\n",
    "    # y = (vzdot_model(graph, params)[:, :-1, :]).flatten()\n",
    "    x = graph.nodes[\"acceleration\"]\n",
    "    _,y = jnp.split(vzdot_model(graph, params), indices_or_sections=2, axis=1)\n",
    "    return jnp.sqrt(jnp.square(x).sum(2)[:,:-1]).flatten(), jnp.sqrt(jnp.square(x).sum(2)[:,:-1]).flatten()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for g in tqdm(bDATA(250)):\n",
    "    a, b = get_acceleration(g, params)\n",
    "    x += [a]\n",
    "    y += [b]\n",
    "\n",
    "x = jnp.hstack(x)\n",
    "y = jnp.hstack(y)\n",
    "\n",
    "\n",
    "min_ = min(x.min(), y.min())\n",
    "max_ = max(x.max(), y.max())\n",
    "range_ = [min_, max_]\n",
    "\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.plot(range_, range_, \"r--\")\n",
    "plt.xlabel(\"Force$_{LJ}$\")\n",
    "plt.ylabel(\"Force$_{HGNN}$\")\n",
    "plt.text(0.15, 0.85, f\"R$^2$ = {r2_score(x, y):.2f}\",\n",
    "         transform=plt.gca().transAxes)\n",
    "\n",
    "# plt.xlim([0, 200])\n",
    "# plt.ylim([0, 200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vzdot_model = jit(lambda *args: vmap(zdot_model, in_axes=(0, None))(*args))\n",
    "\n",
    "def get_acceleration(graph, params):    \n",
    "    # x = (jnp.hstack([graph.nodes[\"velocity\"], graph.nodes[\"acceleration\"]])[:, :-1, :]).flatten()\n",
    "    # y = (vzdot_model(graph, params)[:, :-1, :]).flatten()\n",
    "    x = graph.nodes[\"acceleration\"]\n",
    "    _,y = jnp.split(vzdot_model(graph, params), indices_or_sections=2, axis=1)\n",
    "    return x,y\n",
    "    # return jnp.sqrt(jnp.square(x).sum(2)[:,:-1]).flatten(), jnp.sqrt(jnp.square(x).sum(2)[:,:-1]).flatten()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for g in tqdm(bDATA(20)):\n",
    "    a, b = get_acceleration(g, params)\n",
    "    x += [a]\n",
    "    y += [b]\n",
    "\n",
    "x = jnp.hstack(x).reshape(-1,3)\n",
    "y = jnp.hstack(y).reshape(-1,3)\n",
    "\n",
    "# min_ = min(x.min(), y.min())\n",
    "# max_ = max(x.max(), y.max())\n",
    "# range_ = [min_, max_]\n",
    "\n",
    "plt.scatter(x[:,0], y[:,0], s=10,label='Fx')\n",
    "plt.scatter(x[:,1], y[:,1], s=10,label='Fy')\n",
    "plt.scatter(x[:,2], y[:,2], s=10,label='Fz')\n",
    "# plt.plot(range_, range_, \"r--\")\n",
    "plt.xlabel(\"Force$_{LJ}$\")\n",
    "plt.ylabel(\"Force$_{HGNN}$\")\n",
    "# plt.text(0.15, 0.85, f\"R$^2$ = {r2_score(x, y):.2f}\",\n",
    "#          transform=plt.gca().transAxes)\n",
    "\n",
    "plt.legend()\n",
    "# plt.xlim([0, 200])\n",
    "# plt.ylim([0, 200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ke_ac_pr(graph, params):\n",
    "    ke_actual = 0.5*jnp.square(graph.nodes['velocity']).sum(1)[:-1]\n",
    "    vij, vi, KE, drij = model.apply(params,graph)\n",
    "    KE = KE[:-1]\n",
    "    KE = KE + ke_actual[0] - KE[0]\n",
    "    return ke_actual.flatten(), KE.flatten()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for g in tqdm(GRAPHS[:10]):\n",
    "    a, b = get_ke_ac_pr(g, params)\n",
    "    x += [a]\n",
    "    y += [b]\n",
    "\n",
    "x = jnp.hstack(x)\n",
    "y = jnp.hstack(y)\n",
    "\n",
    "min_ = min(x.min(), y.min())\n",
    "max_ = max(x.max(), y.max())\n",
    "range_ = [min_, max_]\n",
    "\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.plot(range_, range_, \"r--\")\n",
    "plt.xlabel(\"KE$_{ac}$\")\n",
    "plt.ylabel(\"KE$_{pr}$\")\n",
    "plt.text(0.15, 0.85, f\"R$^2$ = {r2_score(x, y):.2f}\", transform=plt.gca().transAxes)\n",
    "\n",
    "# vij, vi, KE, drij = model.apply(params,GRAPHS[0])\n",
    "\n",
    "# ke_actual = 0.5*jnp.square(GRAPHS[0].nodes['velocity']).sum(1)[:-1]\n",
    "# KE = KE[:-1]\n",
    "# KE = KE + ke_actual[0] - KE[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_model = model\n",
    "_params = params\n",
    "_graph = GRAPHS[0]\n",
    "# g = GRAPHS[0]\n",
    "# vij, vi, KE, drij = model.apply(params, g)\n",
    "\n",
    "vij, vi, KE, drij = _model.apply(_params,_graph)\n",
    "\n",
    "eij = jnp.sqrt(1e-10 + jnp.square(drij).sum(axis=1))\n",
    "\n",
    "# types_ = jnp.unique(_graph.nodes[\"type\"])\n",
    "\n",
    "for a in range(2):\n",
    "    for b in range(2):\n",
    "        \n",
    "        mask = (_graph.nodes[\"type\"][_graph.senders] == a) & (\n",
    "            _graph.nodes[\"type\"][_graph.receivers] == b)\n",
    "        mask = (eij >= 0.1) & mask\n",
    "        \n",
    "        y = vij[mask]\n",
    "        x = eij[mask]\n",
    "        \n",
    "        mask = jnp.argsort(x)\n",
    "        x = x[mask]\n",
    "        y = y[mask]\n",
    "        y -= y[-1]\n",
    "        if a==0 and b==0:\n",
    "            pe_actual = 0.5*vmap(partial(lnn.LJ, sigma=1.0,epsilon=1.0))(x).flatten()\n",
    "        elif a==0 and b==1:\n",
    "            pe_actual = 0.5*vmap(partial(lnn.LJ, sigma=0.8,epsilon=1.5))(x).flatten()\n",
    "        elif a==1 and b==0:\n",
    "            pe_actual = 0.5*vmap(partial(lnn.LJ, sigma=0.8,epsilon=1.5))(x).flatten()\n",
    "        elif a==1 and b==1:\n",
    "            pe_actual = 0.5*vmap(partial(lnn.LJ, sigma=0.88,epsilon=0.5))(x).flatten()\n",
    "        \n",
    "        ax.plot(pe_actual, y, '.',label=f\"{a}-{b}\")\n",
    "\n",
    "# ax.set_xlim([-2,2])\n",
    "# ax.set_ylim([-2,1])\n",
    "ax.set_xlabel(\"V$_{ij}$ actual\")\n",
    "ax.set_ylabel(\"V$_{ij}$ predicted\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "def get_ke_ac_pr(graph, params):\n",
    "    ke_actual = 0.5*jnp.square(graph.nodes['velocity']).sum(1)[:-1]\n",
    "    vij, vi, KE, drij = model.apply(params,graph)\n",
    "    KE = KE[:-1]\n",
    "    KE = KE + ke_actual[0] - KE[0]\n",
    "    return ke_actual.flatten(), KE.flatten()\n",
    "\n",
    "ke_ac = []\n",
    "ke_pr = []\n",
    "for g in tqdm(GRAPHS):\n",
    "    a, b = get_ke_ac_pr(g, params)\n",
    "    ke_ac += [a]\n",
    "    ke_pr += [b]\n",
    "\n",
    "ke_ac = jnp.hstack(ke_ac)\n",
    "ke_pr = jnp.hstack(ke_pr)\n",
    "\n",
    "vzdot_model = jit(lambda *args: vmap(zdot_model, in_axes=(0, None))(*args))\n",
    "\n",
    "####################################################\n",
    "def get_acceleration(graph, params):    \n",
    "    x = graph.nodes[\"acceleration\"]\n",
    "    _,y = jnp.split(vzdot_model(graph, params), indices_or_sections=2, axis=1)\n",
    "    return x,y\n",
    "    # return jnp.sqrt(jnp.square(x).sum(2)[:,:-1]).flatten(), jnp.sqrt(jnp.square(x).sum(2)[:,:-1]).flatten()\n",
    "\n",
    "a_ac = []\n",
    "a_pr = []\n",
    "for g in tqdm(bDATA(250)):\n",
    "    a, b = get_acceleration(g, params)\n",
    "    a_ac += [a]\n",
    "    a_pr += [b]\n",
    "\n",
    "a_ac = jnp.hstack(a_ac).reshape(-1,3)\n",
    "a_pr = jnp.hstack(a_pr).reshape(-1,3)\n",
    "\n",
    "\n",
    "####################################################\n",
    "def get_pe_ac_pr(graph, params):\n",
    "    vij, vi, KE, drij = model.apply(params, graph)\n",
    "    eij = jnp.sqrt(1e-10 + jnp.square(drij).sum(axis=1))\n",
    "    \n",
    "    # types_ = jnp.unique(graph.nodes[\"type\"])\n",
    "    for a in range(2):\n",
    "        for b in range(2):\n",
    "            mask = (graph.nodes[\"type\"][graph.senders] == a) & (graph.nodes[\"type\"][graph.receivers] == b)\n",
    "            mask = (eij >= 0.1) & mask\n",
    "            \n",
    "            y = vij[mask]\n",
    "            x = eij[mask]\n",
    "            y -= y[-1]\n",
    "            \n",
    "            if a==0 and b==0:\n",
    "                pe_ac_00 = 0.5*vmap(partial(lnn.LJ, sigma=1.0,epsilon=1.0))(x).flatten()\n",
    "                pe_pr_00 = y\n",
    "            elif a==0 and b==1:\n",
    "                pe_ac_01 = 0.5*vmap(partial(lnn.LJ, sigma=0.8,epsilon=1.5))(x).flatten()\n",
    "                pe_pr_01 = y\n",
    "            elif a==1 and b==0:\n",
    "                pe_ac_10 = 0.5*vmap(partial(lnn.LJ, sigma=0.8,epsilon=1.5))(x).flatten()\n",
    "                pe_pr_10 = y\n",
    "            elif a==1 and b==1:\n",
    "                pe_ac_11 = 0.5*vmap(partial(lnn.LJ, sigma=0.88,epsilon=0.5))(x).flatten()\n",
    "                pe_pr_11 = y\n",
    "    pe_pr_00 = pe_pr_00 + pe_ac_00[0] - pe_pr_00[0]\n",
    "    pe_pr_01 = pe_pr_01 + pe_ac_01[0] - pe_pr_01[0]\n",
    "    pe_pr_10 = pe_pr_10 + pe_ac_10[0] - pe_pr_10[0]\n",
    "    pe_pr_11 = pe_pr_11 + pe_ac_11[0] - pe_pr_11[0]\n",
    "    return pe_ac_00, pe_pr_00, pe_ac_01, pe_pr_01, pe_ac_10, pe_pr_10, pe_ac_11, pe_pr_11\n",
    "            \n",
    "all_pe_ac_00 = []\n",
    "all_pe_pr_00 = []\n",
    "all_pe_ac_01 = []\n",
    "all_pe_pr_01 = []\n",
    "all_pe_ac_10 = []\n",
    "all_pe_pr_10 = []\n",
    "all_pe_ac_11 = []\n",
    "all_pe_pr_11 = []\n",
    "\n",
    "for g in tqdm(GRAPHS):\n",
    "    pe_ac_00, pe_pr_00, pe_ac_01, pe_pr_01, pe_ac_10, pe_pr_10, pe_ac_11, pe_pr_11 = get_pe_ac_pr(g, params)\n",
    "    all_pe_ac_00 += [pe_ac_00]\n",
    "    all_pe_pr_00 += [pe_pr_00]\n",
    "    all_pe_ac_01 += [pe_ac_01]\n",
    "    all_pe_pr_01 += [pe_pr_01]\n",
    "    all_pe_ac_10 += [pe_ac_10]\n",
    "    all_pe_pr_10 += [pe_pr_10]\n",
    "    all_pe_ac_11 += [pe_ac_11]\n",
    "    all_pe_pr_11 += [pe_pr_11]\n",
    "\n",
    "all_pe_ac_00 = jnp.hstack(all_pe_ac_00)\n",
    "all_pe_pr_00 = jnp.hstack(all_pe_pr_00)\n",
    "all_pe_ac_01 = jnp.hstack(all_pe_ac_01)\n",
    "all_pe_pr_01 = jnp.hstack(all_pe_pr_01)\n",
    "all_pe_ac_10 = jnp.hstack(all_pe_ac_10)\n",
    "all_pe_pr_10 = jnp.hstack(all_pe_pr_10)\n",
    "all_pe_ac_11 = jnp.hstack(all_pe_ac_11)\n",
    "all_pe_pr_11 = jnp.hstack(all_pe_pr_11)\n",
    "\n",
    "\n",
    "_nexp = {\n",
    "        \"ke_ac\": ke_ac,\n",
    "        \"ke_pr\": ke_pr,\n",
    "        \"a_ac\": a_ac,\n",
    "        \"a_pr\": a_pr,\n",
    "        \"all_pe_ac_00\": all_pe_ac_00,\n",
    "        \"all_pe_pr_00\": all_pe_pr_00,\n",
    "        \"all_pe_ac_01\": all_pe_ac_01,\n",
    "        \"all_pe_pr_01\": all_pe_pr_01,\n",
    "        \"all_pe_ac_10\": all_pe_ac_10,\n",
    "        \"all_pe_pr_10\": all_pe_pr_10,\n",
    "        \"all_pe_ac_11\": all_pe_ac_11,\n",
    "        \"all_pe_pr_11\": all_pe_pr_11\n",
    "    }\n",
    "\n",
    "# savefile(f\"a_ke_pe_error_parameter.pkl\", _nexp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'../data/LJ_125/HGNN_redo/error_parameter.pkl'\n",
    "nexp = pickle.load(open(filename,'rb'))[0]\n",
    "\n",
    "_filename = f'../data/LJ_125/HGNN_redo/a_ke_pe_error_parameter.pkl'\n",
    "_nexp = pickle.load(open(_filename,'rb'))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'../data/LJ_125/HGNN_redo/error_parameter.pkl'\n",
    "nexp = pickle.load(open(filename,'rb'))[0]\n",
    "\n",
    "_filename = f'../data/LJ_125/HGNN_redo/a_ke_pe_error_parameter.pkl'\n",
    "_nexp = pickle.load(open(_filename,'rb'))[0]\n",
    "\n",
    "\n",
    "import matplotlib.ticker as plticker\n",
    "my_color = {0:'r',1:'b'}\n",
    "\n",
    "fig, axs = panel(1,5)\n",
    "# fig, axs = panel(1, 5, figsize=(5*5,5*1))\n",
    "for i in range(75):\n",
    "    _type = GRAPHS[40].nodes['type'][:-1][i]\n",
    "    axs[0].plot(nexp['pos_pr'][:,i,0],nexp['pos_pr'][:,i,1],'.',color = my_color[_type])\n",
    "    axs[1].plot(nexp['pos_ac'][:,i,0],nexp['pos_ac'][:,i,1],'.',color = my_color[_type])\n",
    "\n",
    "    \n",
    "axs[0].plot([], [],'k',ls='none', mew=0,label='Predicted')\n",
    "axs[1].plot([], [],'k',ls='none', mew=0,label='Actual')\n",
    "\n",
    "\n",
    "axs[0].set_xlabel('$q_x$')\n",
    "axs[0].set_ylabel('$q_y$')\n",
    "axs[1].set_xlabel('$q_x$')\n",
    "axs[1].set_ylabel('$q_y$')\n",
    "axs[0].set_xlim([-0.2,4.2])\n",
    "axs[0].set_ylim([-0.2,4.2])\n",
    "axs[1].set_xlim([-0.2,4.2])\n",
    "axs[1].set_ylim([-0.2,4.2])\n",
    "\n",
    "loc = plticker.MultipleLocator(base=1)\n",
    "axs[0].xaxis.set_major_locator(loc)\n",
    "axs[0].yaxis.set_major_locator(loc)\n",
    "axs[1].xaxis.set_major_locator(loc)\n",
    "axs[1].yaxis.set_major_locator(loc)\n",
    "\n",
    "axs[0].legend(loc=1)\n",
    "axs[1].legend(loc=1)\n",
    "\n",
    "\n",
    "####234\n",
    "\n",
    "x = _nexp['ke_ac']\n",
    "y = _nexp['ke_pr']\n",
    "\n",
    "min_ = min(x.min(), y.min())\n",
    "max_ = max(x.max(), y.max())\n",
    "range_ = [min_, max_]\n",
    "\n",
    "r2 = (r2_score(x,y)).round(1)\n",
    "rmse = jnp.array(jnp.sqrt(mean_squared_error(x,y))).round(1)\n",
    "\n",
    "axs[2].plot(x,y,'.', label=f\"$R^2$= {r2} \\nRMSE= {rmse}\")\n",
    "axs[2].plot(range_, range_, \"r--\")\n",
    "axs[2].set_xlabel(\"KE$_{ac}$\")\n",
    "axs[2].set_ylabel(\"KE$_{pr}$\")\n",
    "\n",
    "# axs[2].text(0.15, 0.85, f\"R$^2$ = {r2_score(x, y):.2f}\", transform=plt.gca().transAxes)\n",
    "leg = axs[2].legend(handlelength=0, handletextpad=0, fancybox=True)\n",
    "for item in leg.legendHandles:\n",
    "    item.set_visible(False)\n",
    "\n",
    "\n",
    "x_00 = _nexp['all_pe_ac_00']\n",
    "y_00 = _nexp['all_pe_pr_00']\n",
    "x_01 = _nexp['all_pe_ac_01']\n",
    "y_01 = _nexp['all_pe_pr_01']\n",
    "x_10 = _nexp['all_pe_ac_10']\n",
    "y_10 = _nexp['all_pe_pr_10']\n",
    "x_11 = _nexp['all_pe_ac_11']\n",
    "y_11 = _nexp['all_pe_pr_11']\n",
    "\n",
    "axs[3].plot(x_00, y_00, '*',label=f\"{0}-{0}\",alpha=0.5)\n",
    "axs[3].plot(x_01, y_01, '^',label=f\"{0}-{1}\",alpha=0.5)\n",
    "axs[3].plot(x_10, y_10, 's',label=f\"{1}-{0}\",alpha=0.5)\n",
    "axs[3].plot(x_11, y_11, 'o',label=f\"{1}-{1}\",alpha=0.5)\n",
    "\n",
    "# ax.set_xlim([-2,2])\n",
    "# ax.set_ylim([-2,1])\n",
    "axs[3].set_xlabel(\"V$_{ij}$ actual\")\n",
    "axs[3].set_ylabel(\"V$_{ij}$ predicted\")\n",
    "axs[3].legend()\n",
    "\n",
    "\n",
    "x = _nexp['a_ac']\n",
    "y = _nexp['a_pr']\n",
    "\n",
    "min_ = min(x.min(), y.min())\n",
    "max_ = max(x.max(), y.max())\n",
    "range_ = [min_, max_]\n",
    "\n",
    "r2 = (r2_score(x,y)).round(1)\n",
    "rmse = jnp.array(jnp.sqrt(mean_squared_error(x,y))).round(1)\n",
    "\n",
    "axs[4].plot(x,y,'.', label=f\"$R^2$= {r2} \\nRMSE= {rmse}\")\n",
    "axs[4].plot(range_, range_, \"r--\")\n",
    "axs[4].set_xlabel(\"Force$_{LJ}$\")\n",
    "axs[4].set_ylabel(\"Force$_{HGNN}$\")\n",
    "\n",
    "leg = axs[4].legend(handlelength=0, handletextpad=0, fancybox=True)\n",
    "for item in leg.legendHandles:\n",
    "    item.set_visible(False)\n",
    "\n",
    "# plt.savefig('../results/fig2-75LJ.png',dpi=100)\n",
    "# axs[4].text(0.15, 0.85, f\"R$^2$ = {r2_score(x, y):.2f}\", transform=plt.gca().transAxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(util)\n",
    "import warnings\n",
    "from typing import Any, Iterable, Mapping, NamedTuple, Optional, Union\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "ArrayTree = Union[jnp.ndarray,\n",
    "                  Iterable['ArrayTree'], Mapping[Any, 'ArrayTree']]\n",
    "\n",
    "\n",
    "class GraphsTuple(NamedTuple):\n",
    "    \"\"\"Class for holding graph information.\n",
    "    \"\"\"\n",
    "    nodes: Optional[ArrayTree]\n",
    "    edges: Optional[ArrayTree]\n",
    "    receivers: Optional[jnp.ndarray]  # with integer dtype\n",
    "    senders: Optional[jnp.ndarray]  # with integer dtype\n",
    "    globals: Optional[ArrayTree]\n",
    "    n_node: jnp.ndarray  # with integer dtype\n",
    "    n_edge: jnp.ndarray   # with integer dtype\n",
    "    e_order: Optional[jnp.ndarray]\n",
    "    e_mask: jnp.ndarray\n",
    "    n_mask: jnp.ndarray\n",
    "\n",
    "\n",
    "def pad_graph_with_edges(graph, max_edges):\n",
    "    \"\"\"Pad graph to accomodate max edges (as edges can be dynamic in MD simulations).\n",
    "    \n",
    "    :param graph: graph tuple\n",
    "    :type graph: GraphsTuple\n",
    "    :param max_edges: max number of edges \n",
    "    :type max_edges: int\n",
    "    :return: padded graph tuple\n",
    "    :rtype: GraphsTuple\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pad_with_graphs(graph, graph.n_node.sum()+1, max_edges+1)\n",
    "    except Exception as excp:\n",
    "        warnings.warn(excp)\n",
    "        max_edges += 10\n",
    "        return pad_graph_with_edges(graph, max_edges)\n",
    "\n",
    "\n",
    "def mkgraph(*args, mass=None, max_edges=0, L=None, atoms=None, **kwargs):\n",
    "    \"\"\"Make graph with padding (edges).\n",
    "    \"\"\"\n",
    "    nodes = kwargs[\"nodes\"]\n",
    "    # nodes[\"mass\"] = mass[nodes[\"type\"]]\n",
    "    graph = GraphsTuple(*args,\n",
    "                        e_mask=jnp.ones(kwargs[\"senders\"].shape, dtype=bool),\n",
    "                        n_mask=jnp.ones(jnp.sum(kwargs[\"n_node\"]), dtype=bool),\n",
    "                        **kwargs)\n",
    "    return pad_graph_with_edges(graph, max_edges)\n",
    "\n",
    "\n",
    "def samegraph(*args, L=None, atoms=None, **kwargs):\n",
    "    \"\"\"make graph from dict.\n",
    "    \"\"\"\n",
    "    graph = GraphsTuple(*args,\n",
    "                        e_mask=jnp.ones(kwargs[\"senders\"].shape, dtype=bool),\n",
    "                        n_mask=jnp.ones(jnp.sum(kwargs[\"n_node\"]), dtype=bool),\n",
    "                        **kwargs)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def _batch(graphs, np_):\n",
    "    \"\"\"Returns batched graph given a list of graphs and a numpy-like module.\"\"\"\n",
    "    # Calculates offsets for sender and receiver arrays, caused by concatenating\n",
    "    # the nodes arrays.\n",
    "    offsets = np_.cumsum(\n",
    "        np_.array([0] + [np_.sum(g.n_node) for g in graphs[:-1]]))\n",
    "    \n",
    "    edge_order_offsets = np_.cumsum(\n",
    "        np_.array([0] + [len(g.senders) for g in graphs[:-1]]))\n",
    "    \n",
    "    def _map_concat(nests):\n",
    "        concat = lambda *args: np_.concatenate(args)\n",
    "        return jax.tree_multimap(concat, *nests)\n",
    "    \n",
    "    return GraphsTuple(\n",
    "        n_node=np_.concatenate([g.n_node for g in graphs]),\n",
    "        n_edge=np_.concatenate([g.n_edge for g in graphs]),\n",
    "        nodes=_map_concat([g.nodes for g in graphs]),\n",
    "        edges=_map_concat([g.edges for g in graphs]),\n",
    "        e_mask=_map_concat([g.e_mask for g in graphs]),\n",
    "        n_mask=_map_concat([g.n_mask for g in graphs]),\n",
    "        e_order=_map_concat(\n",
    "            [g.e_order + o for g, o in zip(graphs, edge_order_offsets)]),\n",
    "        globals=_map_concat([g.globals for g in graphs]),\n",
    "        senders=np_.concatenate(\n",
    "            [g.senders + o for g, o in zip(graphs, offsets)]),\n",
    "        receivers=np_.concatenate(\n",
    "            [g.receivers + o for g, o in zip(graphs, offsets)]))\n",
    "\n",
    "\n",
    "def pad_with_graphs(graph: GraphsTuple,\n",
    "                    n_node: int,\n",
    "                    n_edge: int,\n",
    "                    n_graph: int = 2) -> GraphsTuple:\n",
    "    \"\"\"Pads a ``GraphsTuple`` to size by adding computation preserving graphs.\n",
    "    The ``GraphsTuple`` is padded by first adding a dummy graph which contains the\n",
    "    padding nodes and edges, and then empty graphs without nodes or edges.\n",
    "    The empty graphs and the dummy graph do not interfer with the graphnet\n",
    "    calculations on the original graph, and so are computation preserving.\n",
    "    The padding graph requires at least one node and one graph.\n",
    "    This function does not support jax.jit, because the shape of the output\n",
    "    is data-dependent.\n",
    "    Args:\n",
    "    graph: ``GraphsTuple`` padded with dummy graph and empty graphs.\n",
    "    n_node: the number of nodes in the padded ``GraphsTuple``.\n",
    "    n_edge: the number of edges in the padded ``GraphsTuple``.\n",
    "    n_graph: the number of graphs in the padded ``GraphsTuple``. Default is 2,\n",
    "      which is the lowest possible value, because we always have at least one\n",
    "      graph in the original ``GraphsTuple`` and we need one dummy graph for the\n",
    "      padding.\n",
    "    Raises:\n",
    "    ValueError: if the passed ``n_graph`` is smaller than 2.\n",
    "    RuntimeError: if the given ``GraphsTuple`` is too large for the given\n",
    "      padding.\n",
    "    Returns:\n",
    "    A padded ``GraphsTuple``.\n",
    "    \"\"\"\n",
    "    np = jnp\n",
    "    if n_graph < 2:\n",
    "        raise ValueError(\n",
    "            f'n_graph is {n_graph}, which is smaller than minimum value of 2.')\n",
    "    graph = jax.device_get(graph)\n",
    "    pad_n_node = int(n_node - np.sum(graph.n_node))\n",
    "    pad_n_edge = int(n_edge - np.sum(graph.n_edge))\n",
    "    pad_n_graph = int(n_graph - graph.n_node.shape[0])\n",
    "    if pad_n_node <= 0 or pad_n_edge < 0 or pad_n_graph <= 0:\n",
    "        raise RuntimeError(\n",
    "            'Given graph is too large for the given padding. difference: '\n",
    "            f'n_node {pad_n_node}, n_edge {pad_n_edge}, n_graph {pad_n_graph}')\n",
    "    \n",
    "    pad_n_empty_graph = pad_n_graph - 1\n",
    "    \n",
    "    tree_nodes_pad = (\n",
    "        lambda leaf: np.zeros((pad_n_node,) + leaf.shape[1:], dtype=leaf.dtype))\n",
    "    tree_edges_pad = (\n",
    "        lambda leaf: np.zeros((pad_n_edge,) + leaf.shape[1:], dtype=leaf.dtype))\n",
    "    tree_globs_pad = (\n",
    "        lambda leaf: np.zeros((pad_n_graph,) + leaf.shape[1:], dtype=leaf.dtype))\n",
    "    \n",
    "    padding_graph = GraphsTuple(\n",
    "        n_node=np.concatenate(\n",
    "            [np.array([pad_n_node], dtype=np.int64),\n",
    "             np.zeros(pad_n_empty_graph, dtype=np.int64)]),\n",
    "        n_edge=np.concatenate(\n",
    "            [np.array([pad_n_edge], dtype=np.int64),\n",
    "             np.zeros(pad_n_empty_graph, dtype=np.int64)]),\n",
    "        nodes=jax.tree_map(tree_nodes_pad, graph.nodes),\n",
    "        edges=jax.tree_map(tree_edges_pad, graph.edges),\n",
    "        globals=jax.tree_map(tree_globs_pad, graph.globals),\n",
    "        senders=np.zeros(pad_n_edge, dtype=np.int64),\n",
    "        receivers=np.zeros(pad_n_edge, dtype=np.int64),\n",
    "        e_order=jax.tree_map(tree_edges_pad, graph.e_order),\n",
    "        e_mask=jax.tree_map(tree_edges_pad, graph.e_mask),\n",
    "        n_mask=jax.tree_map(tree_nodes_pad, graph.n_mask),\n",
    "    )\n",
    "    return _batch([graph, padding_graph], np_=np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VV_step_actual(graph, params, dt=0.001):\n",
    "    dt = jax_md.util.f64(dt)\n",
    "    \n",
    "    def func(i, graph):\n",
    "        dt_2 = dt*dt\n",
    "        _, A = zdot_actual(graph, params).split(2)\n",
    "        R = graph.nodes[\"position\"]\n",
    "        V = graph.nodes[\"velocity\"]\n",
    "        dR = V * dt + A * dt_2\n",
    "        R, V = shift(R, dR, V)\n",
    "        dict1 = graph._asdict()\n",
    "        dict1[\"nodes\"][\"position\"] = jax_md.util.f64(R)\n",
    "        dict1[\"nodes\"][\"velocity\"] = jax_md.util.f64(V)\n",
    "        _, A_prime = zdot_actual(GraphsTuple(**dict1), params).split(2)\n",
    "        V = V + jax_md.util.f64(0.5) * (A + A_prime) * dt\n",
    "        dict1[\"nodes\"][\"velocity\"] = jax_md.util.f64(V)\n",
    "        return GraphsTuple(**dict1)\n",
    "    \n",
    "    new_graph = jax.lax.fori_loop(0, 100, func, graph)\n",
    "    \n",
    "    return new_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VV_step(graph, params, dt=0.001):\n",
    "    dt = jax_md.util.f64(dt)\n",
    "    \n",
    "    def func(i, graph):\n",
    "        dt_2 = dt*dt\n",
    "        _, A = zdot_model(graph, params).split(2)\n",
    "        R = graph.nodes[\"position\"]\n",
    "        V = graph.nodes[\"velocity\"]\n",
    "        dR = V * dt + A * dt_2\n",
    "        R, V = shift(R, dR, V)\n",
    "        dict1 = graph._asdict()\n",
    "        dict1[\"nodes\"][\"position\"] = jax_md.util.f64(R)\n",
    "        dict1[\"nodes\"][\"velocity\"] = jax_md.util.f64(V)\n",
    "        _, A_prime = zdot_model(GraphsTuple(**dict1), params).split(2)\n",
    "        V = V + jax_md.util.f64(0.5) * (A + A_prime) * dt\n",
    "        dict1[\"nodes\"][\"velocity\"] = jax_md.util.f64(V)\n",
    "        return GraphsTuple(**dict1)\n",
    "    \n",
    "    new_graph = jax.lax.fori_loop(0, 100, func, graph)\n",
    "    \n",
    "    return new_graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.003/100\n",
    "next_graph = jit(lambda graph: VV_step(graph, params, dt=dt))\n",
    "next_graph_actual = jit(lambda graph: VV_step_actual(graph, params, dt=dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH_A = GraphsTuple(**(GRAPHS[0]._asdict()))\n",
    "\n",
    "dump = io.write_dump(f\"../data/LJ_125/ovito/LJ_small/LJ_graph_redo_same_size.dump\")\n",
    "\n",
    "dict1 = GRAPHS[0]._asdict()\n",
    "dict2 = {\"nodes\": {}}\n",
    "dict2[\"nodes\"][\"position\"] = dict1[\"nodes\"][\"position\"][dict1[\"n_mask\"]]\n",
    "dict2[\"nodes\"][\"velocity\"] = dict1[\"nodes\"][\"velocity\"][dict1[\"n_mask\"]]\n",
    "dict2[\"senders\"] = dict1[\"senders\"][dict1[\"e_mask\"]]\n",
    "dict2[\"receivers\"] = dict1[\"receivers\"][dict1[\"e_mask\"]]\n",
    "dict2[\"n_node\"] = jnp.array([len(dict2[\"nodes\"][\"position\"])])\n",
    "\n",
    "box_size = 3.9685026299204984\n",
    "box = {\"x\": {\"x\": box_size}}\n",
    "dump(dict2, box, atoms=atoms, timestep=0)\n",
    "\n",
    "def matrix_index_fn(matrix,type_a,type_b):\n",
    "    return matrix[type_a,type_b]\n",
    "\n",
    "matrix_broadcast_fn=jax.jit(jax.vmap(jax.vmap(matrix_index_fn,(None,0,None)),(None,None,0)))\n",
    "cutoffs:jnp.ndarray =jnp.array([[2.5 ,2.0],[2.0 ,2.2]],dtype=jnp.float64)\n",
    "pair_cutoffs=matrix_broadcast_fn(cutoffs,species,species)\n",
    "temp_g = GraphsTuple(**(GRAPHS[0]._asdict()))#GRAPHS[0]\n",
    "pos_pr=[]\n",
    "vel_pr=[]\n",
    "for i in tqdm(range(1, 100)):\n",
    "    # if i==0:\n",
    "    #     temp_g = GraphsTuple(**(GRAPH_A._asdict()))\n",
    "    \n",
    "    # temp_g = VV_step(temp_g, params, dt=0.001)\n",
    "    temp_g = next_graph(temp_g)\n",
    "        \n",
    "    g = util.make_graph(temp_g.nodes[\"position\"][:-1], displacement_fn,species=species,\n",
    "                        atoms=atoms, V=temp_g.nodes[\"velocity\"][:-1], mass=[1.0, 1.0], cutoff=pair_cutoffs)\n",
    "    temp_g = mkgraph(globals=None, max_edges=5700, **g)\n",
    "    \n",
    "    dict1 = temp_g._asdict()\n",
    "    dict2 = {\"nodes\": {}}\n",
    "    dict2[\"nodes\"][\"position\"] = dict1[\"nodes\"][\"position\"][dict1[\"n_mask\"]]\n",
    "    dict2[\"nodes\"][\"velocity\"] = dict1[\"nodes\"][\"velocity\"][dict1[\"n_mask\"]]\n",
    "    dict2[\"senders\"] = dict1[\"senders\"][dict1[\"e_mask\"]]\n",
    "    dict2[\"receivers\"] = dict1[\"receivers\"][dict1[\"e_mask\"]]\n",
    "    dict2[\"n_node\"] = jnp.array([len(dict2[\"nodes\"][\"position\"])])\n",
    "    \n",
    "    pos_pr += [dict2[\"nodes\"][\"position\"]]\n",
    "    vel_pr += [dict2[\"nodes\"][\"velocity\"]]\n",
    "    \n",
    "    dump(dict2, box, atoms=atoms, timestep=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH_A = GraphsTuple(**(GRAPHS[0]._asdict()))\n",
    "\n",
    "dump = io.write_dump(f\"../data/LJ_125/ovito/LJ_small/LJ_graph_redo_same_size_actual.dump\")\n",
    "\n",
    "dict1 = GRAPHS[0]._asdict()\n",
    "dict2 = {\"nodes\": {}}\n",
    "dict2[\"nodes\"][\"position\"] = dict1[\"nodes\"][\"position\"][dict1[\"n_mask\"]]\n",
    "dict2[\"nodes\"][\"velocity\"] = dict1[\"nodes\"][\"velocity\"][dict1[\"n_mask\"]]\n",
    "dict2[\"senders\"] = dict1[\"senders\"][dict1[\"e_mask\"]]\n",
    "dict2[\"receivers\"] = dict1[\"receivers\"][dict1[\"e_mask\"]]\n",
    "dict2[\"n_node\"] = jnp.array([len(dict2[\"nodes\"][\"position\"])])\n",
    "\n",
    "box_size = 3.9685026299204984\n",
    "box = {\"x\": {\"x\": box_size}}\n",
    "dump(dict2, box, atoms=atoms, timestep=0)\n",
    "\n",
    "def matrix_index_fn(matrix,type_a,type_b):\n",
    "    return matrix[type_a,type_b]\n",
    "\n",
    "matrix_broadcast_fn=jax.jit(jax.vmap(jax.vmap(matrix_index_fn,(None,0,None)),(None,None,0)))\n",
    "cutoffs:jnp.ndarray =jnp.array([[2.5 ,2.0],[2.0 ,2.2]],dtype=jnp.float64)\n",
    "pair_cutoffs=matrix_broadcast_fn(cutoffs,species,species)\n",
    "temp_g = GraphsTuple(**(GRAPHS[0]._asdict()))#GRAPHS[0]\n",
    "\n",
    "pos_ac=[]\n",
    "vel_ac=[]\n",
    "for i in tqdm(range(1, 100)):\n",
    "    # if i==0:\n",
    "    #     temp_g = GraphsTuple(**(GRAPH_A._asdict()))\n",
    "    \n",
    "    # temp_g = VV_step(temp_g, params, dt=0.001)\n",
    "    temp_g = next_graph_actual(temp_g)\n",
    "        \n",
    "    g = util.make_graph(temp_g.nodes[\"position\"][:-1], displacement_fn,species=species,\n",
    "                        atoms=atoms, V=temp_g.nodes[\"velocity\"][:-1], mass=[1.0, 1.0], cutoff=pair_cutoffs)\n",
    "    temp_g = mkgraph(globals=None, max_edges=5700, **g)\n",
    "    dict1 = temp_g._asdict()\n",
    "    dict2 = {\"nodes\": {}}\n",
    "    dict2[\"nodes\"][\"position\"] = dict1[\"nodes\"][\"position\"][dict1[\"n_mask\"]]\n",
    "    dict2[\"nodes\"][\"velocity\"] = dict1[\"nodes\"][\"velocity\"][dict1[\"n_mask\"]]\n",
    "    dict2[\"senders\"] = dict1[\"senders\"][dict1[\"e_mask\"]]\n",
    "    dict2[\"receivers\"] = dict1[\"receivers\"][dict1[\"e_mask\"]]\n",
    "    dict2[\"n_node\"] = jnp.array([len(dict2[\"nodes\"][\"position\"])])\n",
    "    \n",
    "    pos_ac += [dict2[\"nodes\"][\"position\"]]\n",
    "    vel_ac += [dict2[\"nodes\"][\"velocity\"]]\n",
    "    \n",
    "    dump(dict2, box, atoms=atoms, timestep=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'../data/LJ_125/HGNN_redo/error_parameter.pkl'\n",
    "nexp = pickle.load(open(filename,'rb'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH_A = GraphsTuple(**(GRAPHS[0]._asdict()))\n",
    "\n",
    "R = GRAPH_A.nodes[\"position\"][:-1]\n",
    "V = GRAPH_A.nodes[\"velocity\"][:-1]\n",
    "A = GRAPH_A.nodes['acceleration'][:-1]\n",
    "species = GRAPH_A.nodes[\"type\"][:-1]\n",
    "\n",
    "k = 1\n",
    "L_ = 2*k*L\n",
    "R, KW = util.periodic_image(np.array(R), L=k*L, image=[2, 2, 2], V=V, A=A, species=species)\n",
    "\n",
    "V = KW[\"V\"]\n",
    "A = KW[\"A\"]\n",
    "species = KW[\"species\"]\n",
    "\n",
    "# def sortall(*args, index=None):\n",
    "#     if index is None:\n",
    "#         return args\n",
    "#     else:\n",
    "#         ind = np.argsort(index)\n",
    "#     LIST = list(args) + [index]\n",
    "#     return [i[ind] for i in LIST]\n",
    "\n",
    "# R, V, A, species = sortall(R, V, A, index=species)\n",
    "\n",
    "def matrix_index_fn(matrix,type_a,type_b):\n",
    "    return matrix[type_a,type_b]\n",
    "\n",
    "matrix_broadcast_fn=jax.jit(jax.vmap(jax.vmap(matrix_index_fn,(None,0,None)),(None,None,0)))\n",
    "cutoffs:jnp.ndarray =jnp.array([[2.5 ,2.0],[2.0 ,2.2]],dtype=jnp.float64)\n",
    "pair_cutoffs=matrix_broadcast_fn(cutoffs,species,species)\n",
    "\n",
    "displacement_fn, shift_fn = space.periodic(L_)\n",
    "\n",
    "def shift(R, dR, V):\n",
    "    return shift_fn(R, dR), V\n",
    "\n",
    "def displacement(R1, R2):\n",
    "    return vmap(displacement_fn, in_axes=(0, 0))(R1, R2)\n",
    "\n",
    "box = {\"x\": {\"x\": L_}}\n",
    "\n",
    "atoms = {\n",
    "    \"A\": sum(species == 0),\n",
    "    \"B\": sum(species == 1)\n",
    "}\n",
    "\n",
    "g = util.make_graph(R, displacement_fn, species = species, atoms=atoms,V=V, A = A, mass=[1.0, 1.0], cutoff=pair_cutoffs)\n",
    "\n",
    "max_edges = 50000 #len(g[\"senders\"])\n",
    "temp_g = mkgraph(globals=None, max_edges=max_edges, **g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "model = HGNN(len(np.unique(species)),\n",
    "             displacement_fn=displacement,\n",
    "             layer_norm=True,\n",
    "             use_ke_model=True,\n",
    "             use_edge_model=True,\n",
    "             node_global_latent_size=10,\n",
    "             node_mp_latent_size=10,\n",
    "             edge_mp_latent_size=10,\n",
    "             layer_hidden_dim=10,\n",
    "             num_mlp_layers=2,\n",
    "             message_passing_steps=2,\n",
    "             )\n",
    "\n",
    "def Hmodel(graph, params):\n",
    "    PEij, PEi, KE, _ = model.apply(params, graph)\n",
    "    return KE.sum() + PEij.sum() #+ PEi.sum()\n",
    "\n",
    "\n",
    "########################\n",
    "model_actual = HGNN(len(np.unique(species)),\n",
    "             displacement_fn=displacement,\n",
    "             layer_norm=True,\n",
    "             use_ke_model=False,\n",
    "             use_edge_model=False,\n",
    "             node_global_latent_size=10,\n",
    "             node_mp_latent_size=10,\n",
    "             edge_mp_latent_size=10,\n",
    "             layer_hidden_dim=10,\n",
    "             num_mlp_layers=2,\n",
    "             message_passing_steps=2,\n",
    "             )\n",
    "\n",
    "# params = model_actual.init(key, GRAPHS[0])\n",
    "\n",
    "def Hactual(graph, params):\n",
    "    PEij, PEi, KE, _ = model_actual.apply(params, graph)\n",
    "    return KE.sum() + PEij.sum() #+ PEi.sum()\n",
    "\n",
    "# #####################\n",
    "zdot_model, lamda_force_model = get_zdot_lambda(*temp_g.nodes[\"position\"].shape[-2:], Hmodel)\n",
    "zdot_actual, lamda_force_actual = get_zdot_lambda(*temp_g.nodes[\"position\"].shape[-2:], Hactual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# make_energy_plot(ax,model,params,GRAPHS[0])\n",
    "make_energy_plot(ax,model,params,temp_g)\n",
    "# make_energy_plot(ax,model,params,GRAPHS[10])\n",
    "# make_energy_plot(ax,model,params,GRAPHS[100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "def get_ke_ac_pr(graph, params):\n",
    "    ke_actual = 0.5*jnp.square(graph.nodes['velocity']).sum(1)[:-1]\n",
    "    vij, vi, KE, drij = model.apply(params,graph)\n",
    "    KE = KE[:-1]\n",
    "    KE = KE + ke_actual[0] - KE[0]\n",
    "    return ke_actual.flatten(), KE.flatten()\n",
    "\n",
    "####################################################\n",
    "def get_acceleration(graph, params):    \n",
    "    x = graph.nodes[\"acceleration\"]\n",
    "    _,y = jnp.split(zdot_model(graph, params), indices_or_sections=2, axis=0)\n",
    "    return x,y\n",
    "    # return jnp.sqrt(jnp.square(x).sum(2)[:,:-1]).flatten(), jnp.sqrt(jnp.square(x).sum(2)[:,:-1]).flatten()\n",
    "\n",
    "####################################################\n",
    "def get_pe_ac_pr(graph, params):\n",
    "    vij, vi, KE, drij = model.apply(params, graph)\n",
    "    eij = jnp.sqrt(1e-10 + jnp.square(drij).sum(axis=1))\n",
    "    \n",
    "    # types_ = jnp.unique(graph.nodes[\"type\"])\n",
    "    for a in range(2):\n",
    "        for b in range(2):\n",
    "            mask = (graph.nodes[\"type\"][graph.senders] == a) & (graph.nodes[\"type\"][graph.receivers] == b)\n",
    "            mask = (eij >= 0.1) & mask\n",
    "            \n",
    "            y = vij[mask]\n",
    "            x = eij[mask]\n",
    "            y -= y[-1]\n",
    "            \n",
    "            if a==0 and b==0:\n",
    "                pe_ac_00 = 0.5*vmap(partial(lnn.LJ, sigma=1.0,epsilon=1.0))(x).flatten()\n",
    "                pe_pr_00 = y\n",
    "            elif a==0 and b==1:\n",
    "                pe_ac_01 = 0.5*vmap(partial(lnn.LJ, sigma=0.8,epsilon=1.5))(x).flatten()\n",
    "                pe_pr_01 = y\n",
    "            elif a==1 and b==0:\n",
    "                pe_ac_10 = 0.5*vmap(partial(lnn.LJ, sigma=0.8,epsilon=1.5))(x).flatten()\n",
    "                pe_pr_10 = y\n",
    "            elif a==1 and b==1:\n",
    "                pe_ac_11 = 0.5*vmap(partial(lnn.LJ, sigma=0.88,epsilon=0.5))(x).flatten()\n",
    "                pe_pr_11 = y\n",
    "    pe_pr_00 = pe_pr_00 + pe_ac_00[0] - pe_pr_00[0]\n",
    "    pe_pr_01 = pe_pr_01 + pe_ac_01[0] - pe_pr_01[0]\n",
    "    pe_pr_10 = pe_pr_10 + pe_ac_10[0] - pe_pr_10[0]\n",
    "    pe_pr_11 = pe_pr_11 + pe_ac_11[0] - pe_pr_11[0]\n",
    "    return pe_ac_00, pe_pr_00, pe_ac_01, pe_pr_01, pe_ac_10, pe_pr_10, pe_ac_11, pe_pr_11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH_A = GraphsTuple(**(GRAPHS[0]._asdict()))\n",
    "\n",
    "dump_pr = io.write_dump(f\"../data/LJ_125/ovito/LJ_small/LJ_graph_redo_pr.dump\")\n",
    "dump_ac = io.write_dump(f\"../data/LJ_125/ovito/LJ_small/LJ_graph_redo_ac.dump\")\n",
    "\n",
    "dict1 = temp_g._asdict()\n",
    "dict2 = {\"nodes\": {}}\n",
    "dict2[\"nodes\"][\"position\"] = dict1[\"nodes\"][\"position\"][dict1[\"n_mask\"]]\n",
    "dict2[\"nodes\"][\"velocity\"] = dict1[\"nodes\"][\"velocity\"][dict1[\"n_mask\"]]\n",
    "dict2[\"senders\"] = dict1[\"senders\"][dict1[\"e_mask\"]]\n",
    "dict2[\"receivers\"] = dict1[\"receivers\"][dict1[\"e_mask\"]]\n",
    "dict2[\"n_node\"] = jnp.array([len(dict2[\"nodes\"][\"position\"])])\n",
    "dump_pr(dict2, box, atoms=atoms, timestep=0)\n",
    "dump_ac(dict2, box, atoms=atoms, timestep=0)\n",
    "\n",
    "def matrix_index_fn(matrix,type_a,type_b):\n",
    "    return matrix[type_a,type_b]\n",
    "\n",
    "pos_ac=[]\n",
    "vel_ac=[]\n",
    "pos_pr=[]\n",
    "vel_pr=[]\n",
    "ke_ac = []\n",
    "ke_pr = []\n",
    "a_ac = []\n",
    "a_pr = []\n",
    "all_pe_ac_00 = []\n",
    "all_pe_pr_00 = []\n",
    "all_pe_ac_01 = []\n",
    "all_pe_pr_01 = []\n",
    "all_pe_ac_10 = []\n",
    "all_pe_pr_10 = []\n",
    "all_pe_ac_11 = []\n",
    "all_pe_pr_11 = []\n",
    "\n",
    "for i in tqdm(range(1, 100)):\n",
    "    # if i==0:\n",
    "    #     temp_g = GraphsTuple(**(GRAPH_A._asdict()))\n",
    "    \n",
    "    # temp_g = VV_step(temp_g, params, dt=0.001)\n",
    "    # temp_g = next_graph_actual(temp_g)\n",
    "    if i==0:\n",
    "        temp_g_pr = next_graph(temp_g)\n",
    "        temp_g_ac = next_graph_actual(temp_g)\n",
    "    else:\n",
    "        temp_g_pr = next_graph(temp_g_pr)\n",
    "        temp_g_ac = next_graph_actual(temp_g_ac)\n",
    "        \n",
    "    g_pr = util.make_graph(temp_g_pr.nodes[\"position\"][:-1], displacement_fn,species=species,\n",
    "                        atoms=atoms, V=temp_g_pr.nodes[\"velocity\"][:-1], mass=[1.0, 1.0], cutoff=pair_cutoffs)\n",
    "    \n",
    "    g_ac = util.make_graph(temp_g_ac.nodes[\"position\"][:-1], displacement_fn,species=species,\n",
    "                        atoms=atoms, V=temp_g_ac.nodes[\"velocity\"][:-1], mass=[1.0, 1.0], cutoff=pair_cutoffs)\n",
    "    \n",
    "    temp_g_pr = mkgraph(globals=None, max_edges=50000, **g_pr)\n",
    "    temp_g_ac = mkgraph(globals=None, max_edges=50000, **g_ac)\n",
    "\n",
    "    dict1 = temp_g_pr._asdict()\n",
    "    dict2 = {\"nodes\": {}}\n",
    "    dict2[\"nodes\"][\"position\"] = dict1[\"nodes\"][\"position\"][dict1[\"n_mask\"]]\n",
    "    dict2[\"nodes\"][\"velocity\"] = dict1[\"nodes\"][\"velocity\"][dict1[\"n_mask\"]]\n",
    "    dict2[\"senders\"] = dict1[\"senders\"][dict1[\"e_mask\"]]\n",
    "    dict2[\"receivers\"] = dict1[\"receivers\"][dict1[\"e_mask\"]]\n",
    "    dict2[\"n_node\"] = jnp.array([len(dict2[\"nodes\"][\"position\"])])\n",
    "    \n",
    "    pos_pr += [dict2[\"nodes\"][\"position\"]]\n",
    "    vel_pr += [dict2[\"nodes\"][\"velocity\"]]\n",
    "    \n",
    "    dump_pr(dict2, box, atoms=atoms, timestep=i)\n",
    "    \n",
    "    dict1 = temp_g_ac._asdict()\n",
    "    dict2 = {\"nodes\": {}}\n",
    "    dict2[\"nodes\"][\"position\"] = dict1[\"nodes\"][\"position\"][dict1[\"n_mask\"]]\n",
    "    dict2[\"nodes\"][\"velocity\"] = dict1[\"nodes\"][\"velocity\"][dict1[\"n_mask\"]]\n",
    "    dict2[\"senders\"] = dict1[\"senders\"][dict1[\"e_mask\"]]\n",
    "    dict2[\"receivers\"] = dict1[\"receivers\"][dict1[\"e_mask\"]]\n",
    "    dict2[\"n_node\"] = jnp.array([len(dict2[\"nodes\"][\"position\"])])\n",
    "    \n",
    "    pos_ac += [dict2[\"nodes\"][\"position\"]]\n",
    "    vel_ac += [dict2[\"nodes\"][\"velocity\"]]\n",
    "    \n",
    "    dump_ac(dict2, box, atoms=atoms, timestep=i)\n",
    "    \n",
    "    a, b = get_ke_ac_pr(temp_g_pr, params)\n",
    "    ke_ac += [a]\n",
    "    ke_pr += [b]\n",
    "    \n",
    "    a, b = get_acceleration(temp_g_pr, params)\n",
    "    a_ac += [a]\n",
    "    a_pr += [b]\n",
    "        \n",
    "    pe_ac_00, pe_pr_00, pe_ac_01, pe_pr_01, pe_ac_10, pe_pr_10, pe_ac_11, pe_pr_11 = get_pe_ac_pr(temp_g_pr, params)\n",
    "    all_pe_ac_00 += [pe_ac_00]\n",
    "    all_pe_pr_00 += [pe_pr_00]\n",
    "    all_pe_ac_01 += [pe_ac_01]\n",
    "    all_pe_pr_01 += [pe_pr_01]\n",
    "    all_pe_ac_10 += [pe_ac_10]\n",
    "    all_pe_pr_10 += [pe_pr_10]\n",
    "    all_pe_ac_11 += [pe_ac_11]\n",
    "    all_pe_pr_11 += [pe_pr_11]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_pe_ac_00 = jnp.hstack(all_pe_ac_00)\n",
    "# all_pe_pr_00 = jnp.hstack(all_pe_pr_00)\n",
    "# all_pe_ac_01 = jnp.hstack(all_pe_ac_01)\n",
    "# all_pe_pr_01 = jnp.hstack(all_pe_pr_01)\n",
    "# all_pe_ac_10 = jnp.hstack(all_pe_ac_10)\n",
    "# all_pe_pr_10 = jnp.hstack(all_pe_pr_10)\n",
    "# all_pe_ac_11 = jnp.hstack(all_pe_ac_11)\n",
    "# all_pe_pr_11 = jnp.hstack(all_pe_pr_11)\n",
    "\n",
    "# a_ac = jnp.hstack(a_ac).reshape(-1,3)\n",
    "a_pr = jnp.hstack(a_pr).reshape(-1,3)\n",
    "a_ac = a_pr\n",
    "\n",
    "ke_ac = jnp.hstack(ke_ac)\n",
    "ke_pr = jnp.hstack(ke_pr)\n",
    "\n",
    "_nexp = {\n",
    "        \"pos_ac\": jnp.array(pos_ac),\n",
    "        \"vel_ac\": jnp.array(vel_ac),\n",
    "        \"pos_pr\": jnp.array(pos_pr),\n",
    "        \"vel_pr\": jnp.array(vel_pr),\n",
    "        \"ke_ac\": ke_ac,\n",
    "        \"ke_pr\": ke_pr,\n",
    "        \"a_ac\": a_ac,\n",
    "        \"a_pr\": a_pr,\n",
    "        \"all_pe_ac_00\": all_pe_ac_00,\n",
    "        \"all_pe_pr_00\": all_pe_pr_00,\n",
    "        \"all_pe_ac_01\": all_pe_ac_01,\n",
    "        \"all_pe_pr_01\": all_pe_pr_01,\n",
    "        \"all_pe_ac_10\": all_pe_ac_10,\n",
    "        \"all_pe_pr_10\": all_pe_pr_10,\n",
    "        \"all_pe_ac_11\": all_pe_ac_11,\n",
    "        \"all_pe_pr_11\": all_pe_pr_11\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile(f\"error_parameter_lj_gen.pkl\", _nexp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_nexp_lj = _nexp.copy()\n",
    "\n",
    "fig,axs = panel(1,5)\n",
    "##############################################################\n",
    "############################ LJ ##############################\n",
    "##############################################################\n",
    "\n",
    "_type = species\n",
    "\n",
    "# np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
    "#        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "#        1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
    "#        0, 0, 0, 1, 0, 0, 0, 0, 1])\n",
    "\n",
    "\n",
    "\n",
    "my_color = {0:'r',1:'b'}\n",
    "\n",
    "for i in range(600):\n",
    "    axs[0].plot(_nexp_lj['pos_pr'][:,i,0],_nexp_lj['pos_pr'][:,i,1],'.',color = my_color[_type[i]])\n",
    "    axs[1].plot(_nexp_lj['pos_ac'][:,i,0],_nexp_lj['pos_ac'][:,i,1],'.',color = my_color[_type[i]])\n",
    "\n",
    "\n",
    "axs[0].plot([], [],'k',ls='none', mew=0,label='Predicted')\n",
    "axs[1].plot([], [],'k',ls='none', mew=0,label='Actual')\n",
    "\n",
    "\n",
    "axs[0].set_xlabel('$q_x$')\n",
    "axs[0].set_ylabel('$q_y$')\n",
    "axs[1].set_xlabel('$q_x$')\n",
    "axs[1].set_ylabel('$q_y$')\n",
    "# axs[0].set_xlim([-0.2,4.2])\n",
    "# axs[0].set_ylim([-0.2,4.2])\n",
    "# axs[1].set_xlim([-0.2,4.2])\n",
    "# axs[1].set_ylim([-0.2,4.2])\n",
    "\n",
    "# loc = plticker.MultipleLocator(base=1)\n",
    "# axs[0].xaxis.set_major_locator(loc)\n",
    "# axs[0].yaxis.set_major_locator(loc)\n",
    "# axs[1].xaxis.set_major_locator(loc)\n",
    "# axs[1].yaxis.set_major_locator(loc)\n",
    "\n",
    "axs[0].legend(loc=1)\n",
    "axs[1].legend(loc=1)\n",
    "\n",
    "####234\n",
    "x = _nexp_lj['ke_ac']\n",
    "y = _nexp_lj['ke_pr']\n",
    "\n",
    "r2 = (r2_score(x,y)).round(1)\n",
    "rmse = jnp.array(jnp.sqrt(mean_squared_error(x,y))).round(1)\n",
    "\n",
    "axs[2].plot(x,y,'.', label=f\"$R^2$= {r2} \\nRMSE= {rmse}\")\n",
    "axs[2].set_xlabel(\"KE$_{ac}$\")\n",
    "axs[2].set_ylabel(\"KE$_{pr}$\")\n",
    "\n",
    "# axs[2].text(0.15, 0.85, f\"R$^2$ = {r2_score(x, y):.2f}\", transform=plt.gca().transAxes)\n",
    "leg = axs[2].legend(handlelength=0, handletextpad=0, fancybox=True)\n",
    "for item in leg.legendHandles:\n",
    "    item.set_visible(False)\n",
    "\n",
    "min_ = min(x.min(), y.min())\n",
    "max_ = max(x.max(), y.max())\n",
    "range_ = [min_, max_]\n",
    "axs[2].plot(range_, range_, \"r--\")\n",
    "\n",
    "x_00 = _nexp_lj['all_pe_ac_00']\n",
    "y_00 = _nexp_lj['all_pe_pr_00']\n",
    "x_01 = _nexp_lj['all_pe_ac_01']\n",
    "y_01 = _nexp_lj['all_pe_pr_01']\n",
    "x_10 = _nexp_lj['all_pe_ac_10']\n",
    "y_10 = _nexp_lj['all_pe_pr_10']\n",
    "x_11 = _nexp_lj['all_pe_ac_11']\n",
    "y_11 = _nexp_lj['all_pe_pr_11']\n",
    "\n",
    "axs[3].plot(x_00, y_00, '*',label=f\"{0}-{0}\",alpha=0.5)\n",
    "axs[3].plot(x_01, y_01, '^',label=f\"{0}-{1}\",alpha=0.5)\n",
    "axs[3].plot(x_10, y_10, 's',label=f\"{1}-{0}\",alpha=0.5)\n",
    "axs[3].plot(x_11, y_11, 'o',label=f\"{1}-{1}\",alpha=0.5)\n",
    "\n",
    "min_ = min(x_00.min(),y_00.min(),x_01.min(),y_01.min(),x_10.min(),y_10.min(),x_11.min(),y_11.min())\n",
    "max_ = max(x_00.max(),y_00.max(),x_01.max(),y_01.max(),x_10.max(),y_10.max(),x_11.max(),y_11.max())\n",
    "range_ = [min_, max_]\n",
    "axs[3].plot(range_, range_, \"r--\")\n",
    "\n",
    "\n",
    "# ax.set_xlim([-2,2])\n",
    "# ax.set_ylim([-2,1])\n",
    "axs[3].set_xlabel(\"V$_{ij}$ actual\")\n",
    "axs[3].set_ylabel(\"V$_{ij}$ predicted\")\n",
    "axs[3].legend()\n",
    "\n",
    "# loc = plticker.MultipleLocator(base=2)\n",
    "# axs[3].xaxis.set_major_locator(loc)\n",
    "# axs[3].yaxis.set_major_locator(loc)\n",
    "\n",
    "\n",
    "x = _nexp_lj['a_ac']\n",
    "y = _nexp_lj['a_pr']\n",
    "\n",
    "min_ = min(x.min(), y.min())\n",
    "max_ = max(x.max(), y.max())\n",
    "range_ = [min_, max_]\n",
    "axs[4].plot(range_, range_, \"r--\")\n",
    "\n",
    "r2 = (r2_score(x.flatten(),y.flatten())).round(1)\n",
    "rmse = jnp.array(jnp.sqrt(mean_squared_error(x.flatten(),y.flatten()))).round(1)\n",
    "\n",
    "\n",
    "axs[4].plot(x[:,0],y[:,0],'s',label='$F_x$',alpha=0.5)\n",
    "axs[4].plot(x[:,1],y[:,1],'^',label='$F_y$',alpha=0.5)\n",
    "axs[4].plot(x[:,2],y[:,2],'.',label='$F_z$',alpha=0.5)\n",
    "axs[4].legend()\n",
    "\n",
    "axs[4].set_xlabel('$F_{ac}$')\n",
    "axs[4].set_ylabel('$F_{pr}$')\n",
    "# loc = plticker.MultipleLocator(base=250)\n",
    "# axs[4].xaxis.set_major_locator(loc)\n",
    "# axs[4].yaxis.set_major_locator(loc)\n",
    "\n",
    "# axs[4].plot(x,y,'.', label=f\"$R^2$= {r2} \\nRMSE= {rmse}\")\n",
    "# axs[4].plot(range_, range_, \"r--\")\n",
    "# axs[4].set_xlabel(\"Force$_{LJ}$\")\n",
    "# axs[4].set_ylabel(\"Force$_{HGNN}$\")\n",
    "\n",
    "# leg = axs[4].legend(handlelength=0, handletextpad=0, fancybox=True)\n",
    "# for item in leg.legendHandles:\n",
    "#     item.set_visible(False)\n",
    "\n",
    "# plt.savefig('../results/fig2-75LJ.png',dpi=100)\n",
    "# axs[4].text(0.15, 0.85, f\"R$^2$ = {r2_score(x, y):.2f}\", transform=plt.gca().transAxes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEs = []\n",
    "# KEs = []\n",
    "\n",
    "# for g in forward_graphs:\n",
    "#     vij, vi, KE, drij = model.apply(params, g)\n",
    "#     KEs += [KE.sum()]\n",
    "#     PEs += [vij.sum() + vi.sum()]\n",
    "\n",
    "\n",
    "# KEs = jnp.array(KEs)\n",
    "# PEs = jnp.array(PEs)\n",
    "# PEs -= PEs[0]\n",
    "\n",
    "\n",
    "# plt.plot(KEs, label=\"KE\")\n",
    "# plt.plot(PEs, label=\"PE\")\n",
    "# plt.plot(KEs+PEs, label=\"TE\")\n",
    "# plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ab151d5c88bf40103de6d93126d7f825bab1ed9d9f63eb430a2a9c04ef8bcba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
